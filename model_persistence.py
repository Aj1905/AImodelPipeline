import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

import joblib
import pandas as pd
import polars as pl

# ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤‰æ›´
try:
    from .utils import _get_user_choice
except ImportError:
    # ç›´æ¥å®Ÿè¡Œæ™‚ã®ãŸã‚ã®çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    from utils import _get_user_choice


def save_tuning_results_to_joblib(results: dict, target_column: str, feature_columns: list[str]) -> str | None:
    """ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’joblibãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"tuning_results_{target_column}_{timestamp}.joblib"

        save_data = {
            "results": results,
            "target_column": target_column,
            "feature_columns": feature_columns,
            "timestamp": timestamp,
            "feature_count": len(feature_columns),
        }

        joblib.dump(save_data, filename)
        print(f"âœ“ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
        return filename

    except Exception as e:
        print(f"âŒ ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def load_tuning_results_from_joblib(filename: str) -> dict | None:
    """joblibãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’èª­ã¿è¾¼ã¿"""
    try:
        if not os.path.exists(filename):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filename}")
            return None

        data = joblib.load(filename)

        print(f"âœ“ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {filename}")
        print(f"  ä¿å­˜æ—¥æ™‚: {data.get('timestamp', 'ä¸æ˜')}")
        print(f"  ç›®çš„å¤‰æ•°: {data.get('target_column', 'ä¸æ˜')}")
        print(f"  ç‰¹å¾´é‡æ•°: {data.get('feature_count', 'ä¸æ˜')}")

        return data

    except Exception as e:
        print(f"âŒ èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def list_saved_tuning_results() -> list[str]:
    """ä¿å­˜ã•ã‚ŒãŸãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€è¦§è¡¨ç¤º"""
    pattern = "tuning_results_*.joblib"
    files = list(Path(".").glob(pattern))

    if not files:
        print("ä¿å­˜ã•ã‚ŒãŸãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return []

    print(f"\nä¿å­˜ã•ã‚ŒãŸãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœ ({len(files)}å€‹):")

    file_info = []
    for i, file_path in enumerate(files, 1):
        try:
            data = joblib.load(file_path)
            timestamp = data.get("timestamp", "ä¸æ˜")
            target = data.get("target_column", "ä¸æ˜")
            feature_count = data.get("feature_count", "ä¸æ˜")
            strategy = data.get("results", {}).get("strategy", "ä¸æ˜")
            best_score = data.get("results", {}).get("best_score", "ä¸æ˜")

            print(f"  {i}. {file_path.name}")
            print(f"     ä¿å­˜æ—¥æ™‚: {timestamp}")
            print(f"     ç›®çš„å¤‰æ•°: {target}")
            print(f"     ç‰¹å¾´é‡æ•°: {feature_count}")
            print(f"     æ‰‹æ³•: {strategy}")
            print(f"     æœ€è‰¯ã‚¹ã‚³ã‚¢: {best_score}")
            print()

            file_info.append(str(file_path))

        except Exception as e:
            print(f"  {i}. {file_path.name} (èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e})")

    return file_info


def interactive_tuning_result_loader():
    """å¯¾è©±çš„ã«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’èª­ã¿è¾¼ã¿"""
    files = list_saved_tuning_results()

    if not files:
        return None

    try:
        choice = int(input("èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip())
        if 1 <= choice <= len(files):
            selected_file = files[choice - 1]
            return load_tuning_results_from_joblib(selected_file)
        else:
            print(f"1~{len(files)}ã®ç¯„å›²ã§å…¥åŠ›ã—ã¦ãã ã•ã„")
            return None
    except ValueError:
        print("æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return None


def save_model_to_file(model: Any, target_column: str, feature_columns: list[str]) -> str | None:
    """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"model_{target_column}_{timestamp}.joblib"

        save_data = {
            "model": model,
            "target_column": target_column,
            "feature_columns": feature_columns,
            "timestamp": timestamp,
            "feature_count": len(feature_columns),
        }

        joblib.dump(save_data, filename)
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
        return filename

    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def load_model_from_file(filename: str) -> dict | None:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        if not os.path.exists(filename):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filename}")
            return None

        data = joblib.load(filename)

        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {filename}")
        print(f"  ä¿å­˜æ—¥æ™‚: {data.get('timestamp', 'ä¸æ˜')}")
        print(f"  ç›®çš„å¤‰æ•°: {data.get('target_column', 'ä¸æ˜')}")

        # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡æ•°ã‚’å–å¾—
        model = data.get("model")
        if hasattr(model, "_feature_names") and model._feature_names:
            feature_count = len(model._feature_names)
            feature_source = "ãƒ¢ãƒ‡ãƒ«"
        else:
            feature_count = data.get("feature_count", "ä¸æ˜")
            feature_source = "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"

        print(f"  ç‰¹å¾´é‡æ•°: {feature_count} ({feature_source}ã‹ã‚‰å–å¾—)")

        return data

    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def list_saved_models() -> list[str]:
    """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€è¦§è¡¨ç¤º"""
    pattern = "model_*.joblib"
    files = list(Path(".").glob(pattern))

    if not files:
        print("ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return []

    print(f"\nä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ« ({len(files)}å€‹):")

    file_info = []
    for i, file_path in enumerate(files, 1):
        try:
            data = joblib.load(file_path)
            timestamp = data.get("timestamp", "ä¸æ˜")
            target = data.get("target_column", "ä¸æ˜")

            # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡æ•°ã‚’å–å¾—
            model = data.get("model")
            if hasattr(model, "_feature_names") and model._feature_names:
                feature_count = len(model._feature_names)
                feature_source = "ãƒ¢ãƒ‡ãƒ«"
            else:
                feature_count = data.get("feature_count", "ä¸æ˜")
                feature_source = "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"

            print(f"  {i}. {file_path.name}")
            print(f"     ä¿å­˜æ—¥æ™‚: {timestamp}")
            print(f"     ç›®çš„å¤‰æ•°: {target}")
            print(f"     ç‰¹å¾´é‡æ•°: {feature_count} ({feature_source}ã‹ã‚‰å–å¾—)")
            print()

            file_info.append(str(file_path))

        except Exception as e:
            print(f"  {i}. {file_path.name} (èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e})")

    return file_info


def interactive_model_loader():
    """å¯¾è©±çš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    files = list_saved_models()

    if not files:
        return None

    try:
        choice = int(input("èª­ã¿è¾¼ã‚€ãƒ¢ãƒ‡ãƒ«ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip())
        if 1 <= choice <= len(files):
            selected_file = files[choice - 1]
            return load_model_from_file(selected_file)
        else:
            print(f"1~{len(files)}ã®ç¯„å›²ã§å…¥åŠ›ã—ã¦ãã ã•ã„")
            return None
    except ValueError:
        print("æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return None


def _get_feature_columns_from_model(model_data: dict) -> list[str]:
    """ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡åã‚’å–å¾—"""
    model = model_data["model"]

    # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡åã‚’ä½¿ç”¨(ä¿å­˜ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§ã¯ãªã)
    if hasattr(model, "_feature_names") and model._feature_names:
        feature_columns = model._feature_names
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã®å®Ÿéš›ã®ç‰¹å¾´é‡åã‚’ä½¿ç”¨: {len(feature_columns)}å€‹")
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä¿å­˜ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        feature_columns = model_data["feature_columns"]
        print(f"âš ï¸ ä¿å­˜ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡åã‚’ä½¿ç”¨: {len(feature_columns)}å€‹")

    return feature_columns


def _input_feature_individual(feature_columns: list[str]) -> dict[str, float] | None:
    """å€‹åˆ¥å…¥åŠ›ã§ç‰¹å¾´é‡ã‚’å–å¾—"""
    print("\nå„ç‰¹å¾´é‡ã®å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")
    feature_values = {}

    for feature in feature_columns:
        while True:
            try:
                value = input(f"{feature}: ").strip()
                if value.lower() in ["quit", "exit", "q"]:
                    print("äºˆæ¸¬ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                    return None

                # æ•°å€¤ã«å¤‰æ›
                numeric_value = float(value)
                feature_values[feature] = numeric_value
                break
            except ValueError:
                print("âŒ æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: 1.5, 10, -2.3)")

    return feature_values


def _input_feature_bulk(feature_columns: list[str]) -> dict[str, float] | None:
    """ä¸€æ‹¬å…¥åŠ›ã§ç‰¹å¾´é‡ã‚’å–å¾—"""
    print(f"\n{len(feature_columns)}å€‹ã®ç‰¹å¾´é‡ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ã—ã¦ãã ã•ã„:")
    print(f"é †åº: {', '.join(feature_columns)}")
    print("ä¾‹: 1.5,2.3,0.8,10.2")

    while True:
        try:
            values_input = input("å€¤: ").strip()
            if values_input.lower() in ["quit", "exit", "q"]:
                print("äºˆæ¸¬ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                return None

            values = [v.strip() for v in values_input.split(",")]

            if len(values) != len(feature_columns):
                print(f"âŒ {len(feature_columns)}å€‹ã®å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                continue

            # å„å€¤ã‚’æ•°å€¤ã«å¤‰æ›
            feature_values = {}
            for feature, value in zip(feature_columns, values, strict=False):
                try:
                    feature_values[feature] = float(value)
                except ValueError:
                    print(f"âŒ {feature}ã®å€¤ '{value}' ã‚’æ•°å€¤ã«å¤‰æ›ã§ãã¾ã›ã‚“")
                    break
            else:
                return feature_values  # ã™ã¹ã¦ã®å€¤ãŒæ­£å¸¸ã«å¤‰æ›ã•ã‚ŒãŸå ´åˆ

        except Exception as e:
            print(f"âŒ å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {e}")


def _input_feature_from_csv(feature_columns: list[str]) -> dict[str, float] | None:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰¹å¾´é‡ã‚’å–å¾—"""
    print("\nCSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰¹å¾´é‡ã‚’èª­ã¿è¾¼ã¿ã¾ã™")
    print("CSVãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã®å½¢å¼ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:")
    print("- ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã«ç‰¹å¾´é‡å")
    print("- ãƒ‡ãƒ¼ã‚¿è¡Œã«å€¤(ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)")
    print("ä¾‹: sample_features.csv")

    filename = input("CSVãƒ•ã‚¡ã‚¤ãƒ«å: ").strip()

    try:
        if not os.path.exists(filename):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filename}")
            return None

        csv_data = pd.read_csv(filename)

        if len(csv_data) == 0:
            print("âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None

        # æœ€åˆã®è¡Œã‚’ä½¿ç”¨
        row = csv_data.iloc[0]

        # å¿…è¦ãªç‰¹å¾´é‡ãŒã™ã¹ã¦å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        missing_features = [f for f in feature_columns if f not in csv_data.columns]
        if missing_features:
            print(f"âŒ ä»¥ä¸‹ã®ç‰¹å¾´é‡ãŒCSVãƒ•ã‚¡ã‚¤ãƒ«ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {missing_features}")
            print(f"å¿…è¦ãªç‰¹å¾´é‡: {feature_columns}")
            print(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—: {list(csv_data.columns)}")
            return None

        # ç‰¹å¾´é‡ã®å€¤ã‚’å–å¾—
        feature_values = {}
        for feature in feature_columns:
            feature_values[feature] = float(row[feature])

        print(f"âœ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ {len(feature_values)} å€‹ã®ç‰¹å¾´é‡ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return feature_values

    except Exception as e:
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def _get_feature_values(feature_columns: list[str]) -> dict[str, float] | None:
    """ç‰¹å¾´é‡ã®å€¤ã‚’å–å¾—"""
    print("\nå…¥åŠ›æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    input_options = [
        "å€‹åˆ¥å…¥åŠ›(ä¸€ã¤ãšã¤å…¥åŠ›)",
        "ä¸€æ‹¬å…¥åŠ›(ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)",
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿",
    ]

    input_choice = _get_user_choice("å…¥åŠ›æ–¹æ³•:", input_options)

    if input_choice == 1:
        return _input_feature_individual(feature_columns)
    elif input_choice == 2:
        return _input_feature_bulk(feature_columns)
    elif input_choice == 3:
        return _input_feature_from_csv(feature_columns)
    else:
        print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
        return None


def predict_with_manual_input(model_data: dict) -> dict | None:
    """æ‰‹å‹•å…¥åŠ›ã•ã‚ŒãŸç‰¹å¾´é‡ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
    try:
        model = model_data["model"]
        target_column = model_data["target_column"]

        # ç‰¹å¾´é‡åã‚’å–å¾—
        feature_columns = _get_feature_columns_from_model(model_data)

        print("\n=== æ‰‹å‹•ç‰¹å¾´é‡å…¥åŠ›ã«ã‚ˆã‚‹äºˆæ¸¬ ===")
        print(f"ç›®çš„å¤‰æ•°: {target_column}")
        print(f"å¿…è¦ãªç‰¹å¾´é‡ ({len(feature_columns)}å€‹):")

        # ç‰¹å¾´é‡ã®èª¬æ˜ã‚’è¡¨ç¤º
        for i, feature in enumerate(feature_columns, 1):
            print(f"  {i}. {feature}")

        print("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ:")
        print("- æ•°å€¤ä»¥å¤–ã®å…¥åŠ›ã¯ç„¡åŠ¹ã§ã™")
        print("- äºˆæ¸¬ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã™ã‚‹ã«ã¯ 'quit', 'exit', 'q' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„")
        print("- å°æ•°ç‚¹ã¯ '.' ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„(ä¾‹: 1.5)")

        # ç‰¹å¾´é‡ã®å€¤ã‚’å–å¾—
        feature_values = _get_feature_values(feature_columns)
        if feature_values is None:
            return None

        # å…¥åŠ›ã•ã‚ŒãŸç‰¹å¾´é‡ã‚’DataFrameã«å¤‰æ›
        input_data = pd.DataFrame([feature_values])

        # ç‰¹å¾´é‡ã®é †åºã‚’ãƒ¢ãƒ‡ãƒ«ã®æœŸå¾…ã™ã‚‹é †åºã«åˆã‚ã›ã‚‹
        input_data = input_data[feature_columns]

        print("\nå…¥åŠ›ã•ã‚ŒãŸç‰¹å¾´é‡:")
        for feature in feature_columns:
            print(f"  {feature}: {feature_values[feature]}")

        # äºˆæ¸¬å®Ÿè¡Œ
        print("\näºˆæ¸¬å®Ÿè¡Œä¸­...")
        prediction = model.predict(input_data)[0]

        result = {
            "prediction": prediction,
            "feature_values": feature_values,
            "feature_columns": feature_columns,
            "target_column": target_column,
        }

        print("âœ“ äºˆæ¸¬å®Œäº†!")
        print(f"äºˆæ¸¬å€¤ ({target_column}): {prediction}")

        return result

    except Exception as e:
        print(f"âŒ äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


def predict_with_loaded_model(model_data: dict, test_data: pl.DataFrame) -> dict | None:
    """èª­ã¿è¾¼ã‚“ã ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ"""
    try:
        model = model_data["model"]
        target_column = model_data["target_column"]

        # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡åã‚’ä½¿ç”¨(ä¿å­˜ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§ã¯ãªã)
        if hasattr(model, "_feature_names") and model._feature_names:
            feature_columns = model._feature_names
            print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã®å®Ÿéš›ã®ç‰¹å¾´é‡åã‚’ä½¿ç”¨: {len(feature_columns)}å€‹")
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä¿å­˜ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            feature_columns = model_data["feature_columns"]
            print(f"âš ï¸ ä¿å­˜ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡åã‚’ä½¿ç”¨: {len(feature_columns)}å€‹")

        print(f"äºˆæ¸¬å®Ÿè¡Œä¸­... (ç‰¹å¾´é‡: {len(feature_columns)}å€‹)")

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
        print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶: {test_data.shape}")
        print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ—: {list(test_data.columns)}")
        print(f"å¿…è¦ãªç‰¹å¾´é‡: {feature_columns}")

        # ç‰¹å¾´é‡ã®å­˜åœ¨ç¢ºèª
        missing_features = [col for col in feature_columns if col not in test_data.columns]
        if missing_features:
            print(f"âŒ å¿…è¦ãªç‰¹å¾´é‡ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_features}")
            print(f"åˆ©ç”¨å¯èƒ½ãªåˆ—: {list(test_data.columns)}")
            return None

        # ç‰¹å¾´é‡ã®ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª
        print("ç‰¹å¾´é‡ã®ãƒ‡ãƒ¼ã‚¿å‹:")
        for col in feature_columns:
            dtype = test_data[col].dtype
            print(f"  {col}: {dtype}")

        # æ¬ æå€¤ã®ç¢ºèª
        print("ç‰¹å¾´é‡ã®æ¬ æå€¤:")
        for col in feature_columns:
            null_count = test_data[col].null_count()
            print(f"  {col}: {null_count}å€‹")

        predictions = model.predict(test_data.select(feature_columns))

        result = {
            "predictions": predictions,
            "feature_columns": feature_columns,
            "target_column": target_column,
            "prediction_count": len(predictions),
        }

        print(f"âœ“ äºˆæ¸¬å®Œäº†: {len(predictions)}ä»¶")
        return result

    except Exception as e:
        print(f"âŒ äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback

        print(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        return None


def export_model_predictions(
    predictions: dict, test_data: pl.DataFrame, output_filename: str | None = None
) -> str | None:
    """äºˆæ¸¬çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        if output_filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            target_column = predictions["target_column"]
            output_filename = f"predictions_{target_column}_{timestamp}.csv"

        test_data_pd = test_data.to_pandas()
        test_data_pd[f"{predictions['target_column']}_predicted"] = predictions["predictions"]

        test_data_pd.to_csv(output_filename, index=False)

        print(f"âœ“ äºˆæ¸¬çµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ: {output_filename}")
        print(f"  ãƒ‡ãƒ¼ã‚¿æ•°: {len(test_data_pd)}è¡Œ")
        print(f"  åˆ—æ•°: {len(test_data_pd.columns)}åˆ—")

        return output_filename

    except Exception as e:
        print(f"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None


if __name__ == "__main__":
    print("=== ãƒ¢ãƒ‡ãƒ«æ°¸ç¶šåŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ===")
    print("ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç›´æ¥å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    print("ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
    print("\nåˆ©ç”¨å¯èƒ½ãªé–¢æ•°:")
    print("- save_tuning_results_to_joblib()")
    print("- load_tuning_results_from_joblib()")
    print("- list_saved_tuning_results()")
    print("- interactive_tuning_result_loader()")
    print("- save_model_to_file()")
    print("- load_model_from_file()")
    print("- list_saved_models()")
    print("- interactive_model_loader()")
    print("- predict_with_manual_input()")
    print("- predict_with_loaded_model()")
    print("- export_model_predictions()")
