{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量生成汎用スクリプト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store_code store_name        date time_block  time   sales  customer_count  \\\n",
      "0         191  横浜ベイクォーター  2023-05-01          L    10       0               0   \n",
      "1         191  横浜ベイクォーター  2023-05-01          L    11   67498              28   \n",
      "2         191  横浜ベイクォーター  2023-05-01          L    12  111166              46   \n",
      "3         191  横浜ベイクォーター  2023-05-01          L    13   67466              38   \n",
      "4         191  横浜ベイクォーター  2023-05-01          L    14   41705              19   \n",
      "\n",
      "   party_count  sales_target  prev_year_same_weekday_sales  \\\n",
      "0            0          2000                          3219   \n",
      "1           14         74000                         76436   \n",
      "2           21         79000                         81592   \n",
      "3           22         82000                         84861   \n",
      "4           12         42000                         43987   \n",
      "\n",
      "   prev_year_same_date_sales  dow  \n",
      "0                          0  Mon  \n",
      "1                     115318  Mon  \n",
      "2                      93527  Mon  \n",
      "3                      24049  Mon  \n",
      "4                      75467  Mon  \n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    QuantileTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "\n",
    "df = pd.read_csv('../notebooks/BQ.csv')\n",
    "# df = pd.read_excel('../data/キリンシティ時間帯別売り上げ/23年5月~25年5月時間帯別売上.xlsx')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの基本情報を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "データ基本情報\n",
      "==================================================\n",
      "データ形状: (9224, 12)\n",
      "数値列 (8): ['store_code', 'time', 'sales', 'customer_count', 'party_count', 'sales_target', 'prev_year_same_weekday_sales', 'prev_year_same_date_sales']\n",
      "カテゴリ列 (4): ['store_name', 'date', 'time_block', 'dow']\n",
      "欠損値のある列 (0): []\n",
      "\n",
      "=== 各列の詳細 ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9224 entries, 0 to 9223\n",
      "Data columns (total 12 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   store_code                    9224 non-null   int64 \n",
      " 1   store_name                    9224 non-null   object\n",
      " 2   date                          9224 non-null   object\n",
      " 3   time_block                    9224 non-null   object\n",
      " 4   time                          9224 non-null   int64 \n",
      " 5   sales                         9224 non-null   int64 \n",
      " 6   customer_count                9224 non-null   int64 \n",
      " 7   party_count                   9224 non-null   int64 \n",
      " 8   sales_target                  9224 non-null   int64 \n",
      " 9   prev_year_same_weekday_sales  9224 non-null   int64 \n",
      " 10  prev_year_same_date_sales     9224 non-null   int64 \n",
      " 11  dow                           9224 non-null   object\n",
      "dtypes: int64(8), object(4)\n",
      "memory usage: 864.9+ KB\n",
      "None\n",
      "\n",
      "=== 統計サマリ ===\n",
      "        store_code store_name        date time_block         time  \\\n",
      "count       9224.0       9224        9224       9224  9224.000000   \n",
      "unique         NaN          1         762          3          NaN   \n",
      "top            NaN  横浜ベイクォーター  2023-11-18          L          NaN   \n",
      "freq           NaN       9224          24       5383          NaN   \n",
      "mean         191.0        NaN         NaN        NaN    16.255963   \n",
      "std            0.0        NaN         NaN        NaN     3.715350   \n",
      "min          191.0        NaN         NaN        NaN     0.000000   \n",
      "25%          191.0        NaN         NaN        NaN    13.000000   \n",
      "50%          191.0        NaN         NaN        NaN    16.000000   \n",
      "75%          191.0        NaN         NaN        NaN    19.000000   \n",
      "max          191.0        NaN         NaN        NaN    23.000000   \n",
      "\n",
      "                sales  customer_count  party_count   sales_target  \\\n",
      "count     9224.000000     9224.000000  9224.000000    9224.000000   \n",
      "unique            NaN             NaN          NaN            NaN   \n",
      "top               NaN             NaN          NaN            NaN   \n",
      "freq              NaN             NaN          NaN            NaN   \n",
      "mean     51565.131938       19.380312     8.672160   52561.036427   \n",
      "std      44825.553791       15.585010     6.700131   45755.291998   \n",
      "min          0.000000        0.000000     0.000000       0.000000   \n",
      "25%      16621.500000        7.000000     3.000000   17000.000000   \n",
      "50%      40186.500000       16.000000     7.000000   41000.000000   \n",
      "75%      75516.250000       29.000000    13.000000   77000.000000   \n",
      "max     330946.000000       85.000000    33.000000  316000.000000   \n",
      "\n",
      "        prev_year_same_weekday_sales  prev_year_same_date_sales   dow  \n",
      "count                    9224.000000                9224.000000  9224  \n",
      "unique                           NaN                        NaN     7  \n",
      "top                              NaN                        NaN   Sat  \n",
      "freq                             NaN                        NaN  1330  \n",
      "mean                    50509.628144               50476.237099   NaN  \n",
      "std                     45102.059703               45091.739338   NaN  \n",
      "min                         0.000000                   0.000000   NaN  \n",
      "25%                     15257.750000               15238.500000   NaN  \n",
      "50%                     39129.000000               39112.000000   NaN  \n",
      "75%                     74742.250000               74697.000000   NaN  \n",
      "max                    315599.000000              315599.000000   NaN  \n",
      "\n",
      "=== 数値列の分布特性 ===\n",
      "store_code: 歪度=0.000 (ほぼ正規)\n",
      "time: 歪度=-0.407 (ほぼ正規)\n",
      "sales: 歪度=1.202 (右に歪み)\n",
      "customer_count: 歪度=0.868 (ほぼ正規)\n",
      "party_count: 歪度=0.819 (ほぼ正規)\n",
      "sales_target: 歪度=1.247 (右に歪み)\n",
      "prev_year_same_weekday_sales: 歪度=1.226 (右に歪み)\n",
      "prev_year_same_date_sales: 歪度=1.228 (右に歪み)\n",
      "\n",
      "=== カテゴリ列のユニーク値数 ===\n",
      "store_name: 1個のユニーク値 (非欠損値9224個中)\n",
      "date: 762個のユニーク値 (非欠損値9224個中)\n",
      "time_block: 3個のユニーク値 (非欠損値9224個中)\n",
      "dow: 7個のユニーク値 (非欠損値9224個中)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    global df, dff\n",
    "\n",
    "    # dff が定義済み＆空じゃないならそれを使う\n",
    "    if 'dff' in globals() and isinstance(dff, pd.DataFrame) and not dff.empty:\n",
    "        print(\"既存の dff から読み込みます\")\n",
    "        return dff.copy()\n",
    "\n",
    "    # まだ dff が空 or 定義なし → df をコピー\n",
    "    if 'df' in globals() and isinstance(df, pd.DataFrame):\n",
    "        print(\"df から読み込みます\")\n",
    "        dff = df.copy()\n",
    "        return dff.copy()\n",
    "\n",
    "    # 最後の手段としてファイルから読み込む\n",
    "    try:\n",
    "        df = pd.read_csv(\"your_data.csv\", encoding=\"utf-8\")\n",
    "        dff = df.copy()\n",
    "        print(\"ファイルから df を読み込み、dff にコピーしました\")\n",
    "        return dff.copy()\n",
    "    except Exception as e:\n",
    "        print(\"エラー: df も dff も存在せず、ファイル読み込みにも失敗しました。\", e)\n",
    "        return None\n",
    "\n",
    "dff = load_data()\n",
    "print(dff.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "過程状態の使い回し用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff = dff\n",
    "print(dfff.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数値列変換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 数値列一覧 ===\n",
      "1. store_code\n",
      "2. time\n",
      "3. sales\n",
      "4. customer_count\n",
      "5. party_count\n",
      "6. sales_target\n",
      "7. prev_year_same_weekday_sales\n",
      "8. prev_year_same_date_sales\n",
      "\n",
      "=== 数値列の統計情報 ===\n",
      "       store_code         time          sales  customer_count  party_count  \\\n",
      "count      9224.0  9224.000000    9224.000000     9224.000000  9224.000000   \n",
      "mean        191.0    16.255963   51565.131938       19.380312     8.672160   \n",
      "std           0.0     3.715350   44825.553791       15.585010     6.700131   \n",
      "min         191.0     0.000000       0.000000        0.000000     0.000000   \n",
      "25%         191.0    13.000000   16621.500000        7.000000     3.000000   \n",
      "50%         191.0    16.000000   40186.500000       16.000000     7.000000   \n",
      "75%         191.0    19.000000   75516.250000       29.000000    13.000000   \n",
      "max         191.0    23.000000  330946.000000       85.000000    33.000000   \n",
      "\n",
      "        sales_target  prev_year_same_weekday_sales  prev_year_same_date_sales  \n",
      "count    9224.000000                   9224.000000                9224.000000  \n",
      "mean    52561.036427                  50509.628144               50476.237099  \n",
      "std     45755.291998                  45102.059703               45091.739338  \n",
      "min         0.000000                      0.000000                   0.000000  \n",
      "25%     17000.000000                  15257.750000               15238.500000  \n",
      "50%     41000.000000                  39129.000000               39112.000000  \n",
      "75%     77000.000000                  74742.250000               74697.000000  \n",
      "max    316000.000000                 315599.000000              315599.000000  \n",
      "\n",
      "選択された列: sales\n",
      "\n",
      "=== 変換方法一覧 ===\n",
      "1. standard  - 標準化（平均0、標準偏差1）\n",
      "2. log       - 対数変換（歪みを修正、正の値のみ）\n",
      "3. minmax    - MinMax正規化（0-1スケール）\n",
      "4. robust    - Robust Scaling（外れ値に頑健）\n",
      "5. quantile  - Quantile変換（一様分布に変換）\n",
      "6. skip      - 変換をスキップ\n",
      "\n",
      "--- 列 'sales' の詳細情報 ---\n",
      "最小値: 0.000\n",
      "最大値: 330946.000\n",
      "平均値: 51565.132\n",
      "中央値: 40186.500\n",
      "標準偏差: 44825.554\n",
      "歪度: 1.202\n",
      "欠損値数: 0\n",
      "⚠️ 注意: この列には0以下の値が含まれています（対数変換時は自動調整されます）\n",
      "\n",
      "=== 変換実行 ===\n",
      "✓ sales: 標準化完了\n",
      "\n",
      "=== 変換完了 ===\n",
      "変換後の統計情報:\n",
      "              sales\n",
      "count  9.224000e+03\n",
      "mean  -1.232511e-17\n",
      "std    1.000054e+00\n",
      "min   -1.150414e+00\n",
      "25%   -7.795894e-01\n",
      "50%   -2.538563e-01\n",
      "75%    5.343474e-01\n",
      "max    6.232963e+00\n",
      "   store_code store_name        date time_block  time     sales  \\\n",
      "0         191  横浜ベイクォーター  2023-05-01          L    10 -1.150414   \n",
      "1         191  横浜ベイクォーター  2023-05-01          L    11  0.355461   \n",
      "2         191  横浜ベイクォーター  2023-05-01          L    12  1.329690   \n",
      "3         191  横浜ベイクォーター  2023-05-01          L    13  0.354747   \n",
      "4         191  横浜ベイクォーター  2023-05-01          L    14 -0.219979   \n",
      "\n",
      "   customer_count  party_count  sales_target  prev_year_same_weekday_sales  \\\n",
      "0               0            0          2000                          3219   \n",
      "1              28           14         74000                         76436   \n",
      "2              46           21         79000                         81592   \n",
      "3              38           22         82000                         84861   \n",
      "4              19           12         42000                         43987   \n",
      "\n",
      "   prev_year_same_date_sales  dow  \n",
      "0                          0  Mon  \n",
      "1                     115318  Mon  \n",
      "2                      93527  Mon  \n",
      "3                      24049  Mon  \n",
      "4                      75467  Mon  \n"
     ]
    }
   ],
   "source": [
    "def transform_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # 数値列を抽出\n",
    "    numeric_cols = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "    if not numeric_cols:\n",
    "        print(\"数値列が見つかりません\")\n",
    "        return df\n",
    "\n",
    "    print(\"\\n=== 数値列一覧 ===\")\n",
    "    for i, col in enumerate(numeric_cols, 1):\n",
    "        print(f\"{i}. {col}\")\n",
    "\n",
    "    print(\"\\n=== 数値列の統計情報 ===\")\n",
    "    print(df[numeric_cols].describe())\n",
    "\n",
    "    # 変換する列を選択\n",
    "    print(\"\\n=== 列の選択 ===\")\n",
    "    print(\"変換したい列名をカンマ区切りで入力してください（例: column1,column2,column3）\")\n",
    "    print(\"全ての数値列を選択する場合は 'all' と入力してください\")\n",
    "\n",
    "    column_input = input(\"選択: \").strip()\n",
    "\n",
    "    if column_input.lower() == 'all':\n",
    "        selected_cols = numeric_cols\n",
    "    else:\n",
    "        try:\n",
    "            column_names = [x.strip() for x in column_input.split(',')]\n",
    "            selected_cols = [col for col in column_names if col in numeric_cols]\n",
    "            invalid_cols = [col for col in column_names if col not in numeric_cols]\n",
    "            if invalid_cols:\n",
    "                print(f\"警告: 以下の列名は数値列に存在しません: {', '.join(invalid_cols)}\")\n",
    "        except Exception:\n",
    "            print(\"無効な入力です。処理を終了します。\")\n",
    "            return df\n",
    "\n",
    "    if not selected_cols:\n",
    "        print(\"有効な列が選択されませんでした\")\n",
    "        return df\n",
    "\n",
    "    print(f\"\\n選択された列: {', '.join(selected_cols)}\")\n",
    "\n",
    "    # 変換方法の説明\n",
    "    print(\"\\n=== 変換方法一覧 ===\")\n",
    "    print(\"1. standard  - 標準化（平均0、標準偏差1）\")\n",
    "    print(\"2. log       - 対数変換（歪みを修正、正の値のみ）\")\n",
    "    print(\"3. minmax    - MinMax正規化（0-1スケール）\")\n",
    "    print(\"4. robust    - Robust Scaling（外れ値に頑健）\")\n",
    "    print(\"5. quantile  - Quantile変換（一様分布に変換）\")\n",
    "    print(\"6. binarize  - 二値化（閾値で0/1に変換）\")\n",
    "    print(\"7. skip      - 変換をスキップ\")\n",
    "\n",
    "    result_df = df.copy()\n",
    "    transform_config = {}\n",
    "\n",
    "    # 各列の変換方法を選択\n",
    "    for col in selected_cols:\n",
    "        print(f\"\\n--- 列 '{col}' の詳細情報 ---\")\n",
    "        col_data = df[col].dropna()\n",
    "        print(f\"最小値: {col_data.min():.3f}\")\n",
    "        print(f\"最大値: {col_data.max():.3f}\")\n",
    "        print(f\"平均値: {col_data.mean():.3f}\")\n",
    "        print(f\"中央値: {col_data.median():.3f}\")\n",
    "        print(f\"標準偏差: {col_data.std():.3f}\")\n",
    "        print(f\"歪度: {col_data.skew():.3f}\")\n",
    "        print(f\"欠損値数: {df[col].isnull().sum()}\")\n",
    "\n",
    "        if col_data.min() <= 0:\n",
    "            print(\"⚠️ 注意: この列には0以下の値が含まれています（対数変換時は自動調整されます）\")\n",
    "\n",
    "        while True:\n",
    "            method = input(f\"'{col}' の変換方法を選択 (standard/log/minmax/robust/quantile/binarize/skip): \").strip().lower()\n",
    "\n",
    "            if method in ['standard', 'log', 'minmax', 'robust', 'quantile', 'binarize', 'skip']:\n",
    "                if method == 'binarize':\n",
    "                    while True:\n",
    "                        try:\n",
    "                            threshold = float(input(f\"'{col}' の閾値を入力（この値より大きい場合は1、以下は0）: \").strip())\n",
    "                            transform_config[col] = {'method': method, 'threshold': threshold}\n",
    "                            break\n",
    "                        except ValueError:\n",
    "                            print(\"数値を入力してください\")\n",
    "                elif method != 'skip':\n",
    "                    transform_config[col] = method\n",
    "                break\n",
    "            else:\n",
    "                print(\"無効な選択です。再度入力してください。\")\n",
    "\n",
    "    if not transform_config:\n",
    "        print(\"変換する列が選択されませんでした\")\n",
    "        return df\n",
    "\n",
    "    # 変換実行\n",
    "    print(\"\\n=== 変換実行 ===\")\n",
    "\n",
    "    for col, method_config in transform_config.items():\n",
    "        try:\n",
    "            # methodがstrの場合（従来の形式）とdictの場合（binarizeなど）を処理\n",
    "            if isinstance(method_config, str):\n",
    "                method = method_config\n",
    "            else:\n",
    "                method = method_config['method']\n",
    "\n",
    "            if method == 'standard':\n",
    "                scaler = StandardScaler()\n",
    "                result_df[[col]] = scaler.fit_transform(result_df[[col]])\n",
    "                print(f\"✓ {col}: 標準化完了\")\n",
    "\n",
    "            elif method == 'log':\n",
    "                # 負の値がある場合は自動的にシフト\n",
    "                min_val = result_df[col].min()\n",
    "                if min_val <= 0:\n",
    "                    shift = 1 - min_val\n",
    "                    result_df[col] = np.log(result_df[col] + shift)\n",
    "                    print(f\"✓ {col}: 対数変換完了（シフト量: {shift:.3f}）\")\n",
    "                else:\n",
    "                    result_df[col] = np.log(result_df[col])\n",
    "                    print(f\"✓ {col}: 対数変換完了\")\n",
    "\n",
    "            elif method == 'minmax':\n",
    "                scaler = MinMaxScaler()\n",
    "                result_df[[col]] = scaler.fit_transform(result_df[[col]])\n",
    "                print(f\"✓ {col}: MinMax正規化完了\")\n",
    "\n",
    "            elif method == 'robust':\n",
    "                scaler = RobustScaler()\n",
    "                result_df[[col]] = scaler.fit_transform(result_df[[col]])\n",
    "                print(f\"✓ {col}: Robust Scaling完了\")\n",
    "\n",
    "            elif method == 'quantile':\n",
    "                scaler = QuantileTransformer()\n",
    "                result_df[[col]] = scaler.fit_transform(result_df[[col]])\n",
    "                print(f\"✓ {col}: Quantile変換完了\")\n",
    "\n",
    "            elif method == 'binarize':\n",
    "                threshold = method_config['threshold']\n",
    "                new_col = f\"{col}_bin\"\n",
    "                result_df[new_col] = (result_df[col] > threshold).astype(int)\n",
    "                print(f\"✓ {col}: 二値化完了（閾値: {threshold}） -> {new_col}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {col}の変換中にエラーが発生しました: {e!s}\")\n",
    "\n",
    "    print(\"\\n=== 変換完了 ===\")\n",
    "    print(\"変換後の統計情報:\")\n",
    "\n",
    "    # 変換された列と新しく作成された列を取得\n",
    "    display_cols = []\n",
    "    for col, method_config in transform_config.items():\n",
    "        if isinstance(method_config, str):\n",
    "            method = method_config\n",
    "        else:\n",
    "            method = method_config['method']\n",
    "\n",
    "        if method == 'binarize':\n",
    "            # 二値化の場合は新しい列を表示\n",
    "            new_col = f\"{col}_bin\"\n",
    "            if new_col in result_df.columns:\n",
    "                display_cols.append(new_col)\n",
    "        else:\n",
    "            # その他の場合は元の列を表示\n",
    "            display_cols.append(col)\n",
    "\n",
    "    if display_cols:\n",
    "        print(result_df[display_cols].describe())\n",
    "\n",
    "    return result_df\n",
    "\n",
    "dff = transform_features(dff)\n",
    "# dff = transform_features(dfff)\n",
    "\n",
    "print(dff.head())\n",
    "print(f\"\\n変換後のデータ形状: {dff.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # 欠損値のある列を抽出\n",
    "    missing_cols = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "    if not missing_cols:\n",
    "        print(\"欠損値はありません\")\n",
    "        return df\n",
    "\n",
    "    print(\"\\n=== 欠損値のある列一覧 ===\")\n",
    "    for i, col in enumerate(missing_cols, 1):\n",
    "        missing_count = df[col].isna().sum()\n",
    "        missing_rate = (missing_count / len(df)) * 100\n",
    "        col_type = \"数値\" if pd.api.types.is_numeric_dtype(df[col]) else \"カテゴリカル\"\n",
    "        print(f\"{i}. {col} - {missing_count}個 ({missing_rate:.1f}%) [{col_type}]\")\n",
    "\n",
    "    print(\"\\n=== 欠損値詳細情報 ===\")\n",
    "    missing_info = df[missing_cols].isnull().sum()\n",
    "    for col in missing_cols:\n",
    "        total_missing = missing_info[col]\n",
    "        missing_rate = (total_missing / len(df)) * 100\n",
    "        print(f\"{col}: {total_missing}/{len(df)} ({missing_rate:.1f}%)\")\n",
    "\n",
    "    # 補完する列を選択\n",
    "    print(\"\\n=== 列の選択 ===\")\n",
    "    print(\"補完したい列名をカンマ区切りで入力してください（例: age,income,category）\")\n",
    "    print(\"欠損値のある全ての列を選択する場合は 'all' と入力してください\")\n",
    "\n",
    "    column_input = input(\"選択: \").strip()\n",
    "\n",
    "    if column_input.lower() == 'all':\n",
    "        selected_cols = missing_cols\n",
    "    else:\n",
    "        try:\n",
    "            column_names = [x.strip() for x in column_input.split(',')]\n",
    "            selected_cols = [col for col in column_names if col in missing_cols]\n",
    "            invalid_cols = [col for col in column_names if col not in missing_cols]\n",
    "            if invalid_cols:\n",
    "                print(f\"警告: 以下の列名は欠損値のある列に存在しません: {', '.join(invalid_cols)}\")\n",
    "        except Exception:\n",
    "            print(\"無効な入力です。処理を終了します。\")\n",
    "            return df\n",
    "\n",
    "    if not selected_cols:\n",
    "        print(\"有効な列が選択されませんでした\")\n",
    "        return df\n",
    "\n",
    "    print(f\"\\n選択された列: {', '.join(selected_cols)}\")\n",
    "\n",
    "    # 補完方法の説明\n",
    "    print(\"\\n=== 補完方法一覧 ===\")\n",
    "    print(\"数値列で利用可能:\")\n",
    "    print(\"1. mean      - 平均値で補完\")\n",
    "    print(\"2. median    - 中央値で補完\")\n",
    "    print(\"3. mode      - 最頻値で補完\")\n",
    "    print(\"\\n全ての列で利用可能:\")\n",
    "    print(\"4. forward   - 前方補完（前の値で埋める）\")\n",
    "    print(\"5. backward  - 後方補完（後の値で埋める）\")\n",
    "    print(\"6. fill      - 指定値で補完\")\n",
    "    print(\"7. drop      - 欠損値のある行を削除\")\n",
    "    print(\"8. skip      - 補完をスキップ\")\n",
    "\n",
    "    result_df = df.copy()\n",
    "    impute_config = {}\n",
    "    rows_to_drop = set()  # 削除対象の行インデックス\n",
    "\n",
    "    # 各列の補完方法を選択\n",
    "    for col in selected_cols:\n",
    "        print(f\"\\n--- 列 '{col}' の詳細情報 ---\")\n",
    "        is_numeric = pd.api.types.is_numeric_dtype(df[col])\n",
    "        missing_count = df[col].isna().sum()\n",
    "        missing_rate = (missing_count / len(df)) * 100\n",
    "\n",
    "        print(f\"データ型: {'数値' if is_numeric else 'カテゴリカル'}\")\n",
    "        print(f\"欠損値: {missing_count}個 ({missing_rate:.1f}%)\")\n",
    "\n",
    "        if is_numeric:\n",
    "            non_missing = df[col].dropna()\n",
    "            if len(non_missing) > 0:\n",
    "                print(f\"平均値: {non_missing.mean():.3f}\")\n",
    "                print(f\"中央値: {non_missing.median():.3f}\")\n",
    "                if len(non_missing.mode()) > 0:\n",
    "                    print(f\"最頻値: {non_missing.mode().iloc[0]:.3f}\")\n",
    "        else:\n",
    "            value_counts = df[col].value_counts()\n",
    "            print(f\"ユニーク値数: {len(value_counts)}\")\n",
    "            if len(value_counts) > 0:\n",
    "                print(f\"最頻値: {value_counts.index[0]}\")\n",
    "                print(f\"上位3値: {dict(value_counts.head(3))}\")\n",
    "\n",
    "        # 利用可能な方法を表示\n",
    "        available_methods = ['forward', 'backward', 'fill', 'drop', 'skip']\n",
    "        if is_numeric:\n",
    "            available_methods = ['mean', 'median', 'mode'] + available_methods\n",
    "        else:\n",
    "            available_methods = ['mode'] + available_methods\n",
    "\n",
    "        print(f\"利用可能な方法: {', '.join(available_methods)}\")\n",
    "\n",
    "        while True:\n",
    "            method = input(f\"'{col}' の補完方法を選択: \").strip().lower()\n",
    "\n",
    "            if method == 'skip':\n",
    "                break\n",
    "            elif method in available_methods:\n",
    "                if method == 'fill':\n",
    "                    fill_value = input(\"補完する値を入力: \").strip()\n",
    "                    # 数値列の場合は数値に変換を試行\n",
    "                    if is_numeric:\n",
    "                        try:\n",
    "                            fill_value = float(fill_value)\n",
    "                        except ValueError:\n",
    "                            print(\"数値列には数値を入力してください。再度入力してください。\")\n",
    "                            continue\n",
    "                    impute_config[col] = {'method': method, 'fill_value': fill_value}\n",
    "                elif method == 'drop':\n",
    "                    # 削除対象の行を記録\n",
    "                    drop_indices = df[df[col].isna()].index\n",
    "                    rows_to_drop.update(drop_indices)\n",
    "                    print(f\"列'{col}'の欠損値がある{len(drop_indices)}行を削除対象に追加\")\n",
    "                else:\n",
    "                    impute_config[col] = {'method': method}\n",
    "                break\n",
    "            else:\n",
    "                print(\"無効な選択です。再度入力してください。\")\n",
    "\n",
    "    if not impute_config and not rows_to_drop:\n",
    "        print(\"補完する列が選択されませんでした\")\n",
    "        return df\n",
    "\n",
    "    # 補完実行\n",
    "    print(\"\\n=== 補完実行 ===\")\n",
    "\n",
    "    # 行削除を先に実行\n",
    "    if rows_to_drop:\n",
    "        result_df = result_df.drop(index=list(rows_to_drop))\n",
    "        print(f\"✓ {len(rows_to_drop)}行を削除しました\")\n",
    "\n",
    "        # インデックスをリセット\n",
    "        result_df = result_df.reset_index(drop=True)\n",
    "\n",
    "    # 各列の補完を実行\n",
    "    for col, config in impute_config.items():\n",
    "        method = config['method']\n",
    "\n",
    "        try:\n",
    "            missing_before = result_df[col].isna().sum()\n",
    "\n",
    "            if method == 'mean':\n",
    "                fill_value = result_df[col].mean()\n",
    "                result_df[col].fillna(fill_value, inplace=True)\n",
    "                print(f\"✓ {col}: 平均値補完完了 (補完値: {fill_value:.3f})\")\n",
    "\n",
    "            elif method == 'median':\n",
    "                fill_value = result_df[col].median()\n",
    "                result_df[col].fillna(fill_value, inplace=True)\n",
    "                print(f\"✓ {col}: 中央値補完完了 (補完値: {fill_value:.3f})\")\n",
    "\n",
    "            elif method == 'mode':\n",
    "                mode_values = result_df[col].mode()\n",
    "                if len(mode_values) > 0:\n",
    "                    fill_value = mode_values.iloc[0]\n",
    "                    result_df[col].fillna(fill_value, inplace=True)\n",
    "                    print(f\"✓ {col}: 最頻値補完完了 (補完値: {fill_value})\")\n",
    "                else:\n",
    "                    print(f\"❌ {col}: 最頻値が見つかりませんでした\")\n",
    "\n",
    "            elif method == 'forward':\n",
    "                result_df[col].fillna(method='ffill', inplace=True)\n",
    "                print(f\"✓ {col}: 前方補完完了\")\n",
    "\n",
    "            elif method == 'backward':\n",
    "                result_df[col].fillna(method='bfill', inplace=True)\n",
    "                print(f\"✓ {col}: 後方補完完了\")\n",
    "\n",
    "            elif method == 'fill':\n",
    "                fill_value = config['fill_value']\n",
    "                result_df[col].fillna(fill_value, inplace=True)\n",
    "                print(f\"✓ {col}: 指定値補完完了 (補完値: {fill_value})\")\n",
    "\n",
    "            missing_after = result_df[col].isna().sum()\n",
    "            compensated = missing_before - missing_after\n",
    "            if compensated > 0:\n",
    "                print(f\"  → {compensated}個の欠損値を補完\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {col}の補完中にエラーが発生しました: {e!s}\")\n",
    "\n",
    "    print(\"\\n=== 補完完了 ===\")\n",
    "\n",
    "    # 補完後の欠損値状況を確認\n",
    "    remaining_missing = result_df.isnull().sum().sum()\n",
    "    if remaining_missing > 0:\n",
    "        print(f\"残りの欠損値: {remaining_missing}個\")\n",
    "        remaining_cols = result_df.columns[result_df.isna().any()].tolist()\n",
    "        print(f\"欠損値が残っている列: {remaining_cols}\")\n",
    "    else:\n",
    "        print(\"✓ 全ての欠損値が処理されました\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "dff = impute_missing_values(dff)\n",
    "# dff = impute_missing_values(dfff)\n",
    "\n",
    "print(dff.head())\n",
    "print(f\"\\n変換後のデータ形状: {dff.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリ変数のエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== カテゴリカル列一覧 ===\n",
      "1. store_name\n",
      "2. date\n",
      "3. time_block\n",
      "4. dow\n",
      "\n",
      "=== カテゴリカル列の詳細情報 ===\n",
      "store_name: 1個のユニーク値 - ['横浜ベイクォーター']\n",
      "date: 762個のユニーク値 - ['2023-05-01', '2023-05-02', '2023-05-03', '2023-05-04', '2023-05-05']...\n",
      "time_block: 3個のユニーク値 - ['L', 'D', '未使用']\n",
      "dow: 7個のユニーク値 - ['Mon', 'Tue', 'Wed', 'Thu', 'Fri']...\n",
      "\n",
      "選択された列: time_block\n",
      "\n",
      "=== エンコーディング方法一覧 ===\n",
      "1. onehot     - ワンホットエンコーディング（カテゴリ数が少ない場合）\n",
      "2. label      - ラベルエンコーディング（順序関係がある場合）\n",
      "3. frequency  - 頻度エンコーディング（出現頻度で数値化）\n",
      "4. target     - ターゲットエンコーディング（ターゲット変数との関係を利用）\n",
      "5. skip       - エンコーディングをスキップ\n",
      "\n",
      "--- 列 'time_block' の詳細情報 ---\n",
      "ユニーク値数: 3\n",
      "欠損値数: 0\n",
      "上位5つの値: {'L': np.int64(5383), 'D': np.int64(3724), '未使用': np.int64(117)}\n",
      "\n",
      "=== エンコーディング実行 ===\n",
      "✓ time_block: ワンホットエンコーディング完了 -> 2個の新しい特徴量\n",
      "\n",
      "=== エンコーディング完了 ===\n",
      "変換後のDataFrame形状: (9224, 13)\n",
      "   store_code store_name        date  time     sales  customer_count  \\\n",
      "0         191  横浜ベイクォーター  2023-05-01    10 -1.150414               0   \n",
      "1         191  横浜ベイクォーター  2023-05-01    11  0.355461              28   \n",
      "2         191  横浜ベイクォーター  2023-05-01    12  1.329690              46   \n",
      "3         191  横浜ベイクォーター  2023-05-01    13  0.354747              38   \n",
      "4         191  横浜ベイクォーター  2023-05-01    14 -0.219979              19   \n",
      "\n",
      "   party_count  sales_target  prev_year_same_weekday_sales  \\\n",
      "0            0          2000                          3219   \n",
      "1           14         74000                         76436   \n",
      "2           21         79000                         81592   \n",
      "3           22         82000                         84861   \n",
      "4           12         42000                         43987   \n",
      "\n",
      "   prev_year_same_date_sales  dow  time_block_L  time_block_未使用  \n",
      "0                          0  Mon          True           False  \n",
      "1                     115318  Mon          True           False  \n",
      "2                      93527  Mon          True           False  \n",
      "3                      24049  Mon          True           False  \n",
      "4                      75467  Mon          True           False  \n"
     ]
    }
   ],
   "source": [
    "def unified_encoding(df: pd.DataFrame,\n",
    "                    encoding_config: Optional[Dict[str, Dict[str, Any]]] = None,\n",
    "                    interactive: bool = True) -> pd.DataFrame:\n",
    "\n",
    "    result_df = df.copy()\n",
    "    categorical_cols = [col for col in df.columns if not pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "    if not categorical_cols:\n",
    "        print(\"カテゴリカル列が見つかりません\")\n",
    "        return result_df\n",
    "\n",
    "    if encoding_config is None and interactive:\n",
    "        encoding_config = {}\n",
    "\n",
    "        print(\"\\n=== カテゴリカル列一覧 ===\")\n",
    "        for i, col in enumerate(categorical_cols, 1):\n",
    "            print(f\"{i}. {col}\")\n",
    "\n",
    "        print(\"\\n=== カテゴリカル列の詳細情報 ===\")\n",
    "        for col in categorical_cols:\n",
    "            unique_vals = df[col].unique()\n",
    "            print(f\"{col}: {len(unique_vals)}個のユニーク値 - {list(unique_vals)[:5]}{'...' if len(unique_vals) > 5 else ''}\")\n",
    "\n",
    "        column_input = input(\"変換したい列名をカンマ区切りで入力してください（未指定は Enter）: \").strip()\n",
    "\n",
    "        if column_input.lower() == '':\n",
    "            selected_cols = categorical_cols\n",
    "        else:\n",
    "            try:\n",
    "                column_names = [x.strip() for x in column_input.split(',')]\n",
    "                selected_cols = [col for col in column_names if col in categorical_cols]\n",
    "                invalid_cols = [col for col in column_names if col not in categorical_cols]\n",
    "                if invalid_cols:\n",
    "                    print(f\"警告: 以下の列名はカテゴリカル列に存在しません: {', '.join(invalid_cols)}\")\n",
    "            except Exception:\n",
    "                print(\"無効な入力です。処理を終了します。\")\n",
    "                return result_df\n",
    "\n",
    "        if not selected_cols:\n",
    "            print(\"有効な列が選択されませんでした\")\n",
    "            return result_df\n",
    "\n",
    "        print(f\"\\n選択された列: {', '.join(selected_cols)}\")\n",
    "\n",
    "        # エンコーディング方法の説明\n",
    "        print(\"\\n=== エンコーディング方法一覧 ===\")\n",
    "        print(\"1. onehot     - ワンホットエンコーディング（カテゴリ数が少ない場合）\")\n",
    "        print(\"2. label      - ラベルエンコーディング（順序関係がある場合）\")\n",
    "        print(\"3. frequency  - 頻度エンコーディング（出現頻度で数値化）\")\n",
    "        print(\"4. target     - ターゲットエンコーディング（ターゲット変数との関係を利用）\")\n",
    "        print(\"5. skip       - エンコーディングをスキップ\")\n",
    "\n",
    "        for col in selected_cols:\n",
    "            print(f\"\\n--- 列 '{col}' の詳細情報 ---\")\n",
    "            unique_vals = df[col].unique()\n",
    "            value_counts = df[col].value_counts()\n",
    "            print(f\"ユニーク値数: {len(unique_vals)}\")\n",
    "            print(f\"欠損値数: {df[col].isnull().sum()}\")\n",
    "            print(f\"上位5つの値: {dict(value_counts.head())}\")\n",
    "\n",
    "            if len(unique_vals) > 10:\n",
    "                print(\"⚠️ 注意: ユニーク値が多いため、ワンホットエンコーディングは推奨されません\")\n",
    "\n",
    "            while True:\n",
    "                method = input(f\"'{col}' のエンコーディング方法を選択 (onehot/label/frequency/target/skip): \").strip().lower()\n",
    "\n",
    "                if method == 'skip':\n",
    "                    break\n",
    "                elif method in ['onehot', 'label', 'frequency']:\n",
    "                    encoding_config[col] = {'method': method}\n",
    "                    break\n",
    "                elif method == 'target':\n",
    "                    target_col = input(\"ターゲット列名を入力: \").strip()\n",
    "                    if target_col in df.columns:\n",
    "                        encoding_config[col] = {'method': method, 'target_col': target_col}\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"列'{target_col}'が見つかりません。再度入力してください。\")\n",
    "                else:\n",
    "                    print(\"無効な選択です。再度入力してください。\")\n",
    "\n",
    "    if encoding_config is None:\n",
    "        encoding_config = {}\n",
    "\n",
    "    if not encoding_config:\n",
    "        print(\"エンコーディングする列が選択されませんでした\")\n",
    "        return result_df\n",
    "\n",
    "    # エンコーディング実行\n",
    "    print(\"\\n=== エンコーディング実行 ===\")\n",
    "\n",
    "    for col, config in encoding_config.items():\n",
    "        if col not in categorical_cols:\n",
    "            print(f\"❌ 警告: 列'{col}'はカテゴリカル列ではありません\")\n",
    "            continue\n",
    "\n",
    "        method = config.get('method', 'onehot')\n",
    "\n",
    "        try:\n",
    "            if method == 'onehot':\n",
    "                # ワンホットエンコーディング\n",
    "                dummies = pd.get_dummies(result_df[col], prefix=col, drop_first=True)\n",
    "                result_df = pd.concat([result_df.drop(col, axis=1), dummies], axis=1)\n",
    "                print(f\"✓ {col}: ワンホットエンコーディング完了 -> {len(dummies.columns)}個の新しい特徴量\")\n",
    "\n",
    "            elif method == 'label':\n",
    "                # ラベルエンコーディング\n",
    "                le = LabelEncoder()\n",
    "                result_df[col] = le.fit_transform(result_df[col])\n",
    "                print(f\"✓ {col}: ラベルエンコーディング完了\")\n",
    "\n",
    "            elif method == 'frequency':\n",
    "                # 頻度エンコーディング\n",
    "                freq = result_df[col].value_counts(normalize=True)\n",
    "                new_col = f\"{col}_freq\"\n",
    "                result_df[new_col] = result_df[col].map(freq)\n",
    "                print(f\"✓ {col}: 頻度エンコーディング完了 -> {new_col}\")\n",
    "\n",
    "            elif method == 'target':\n",
    "                # ターゲットエンコーディング\n",
    "                target_col = config.get('target_col')\n",
    "                if target_col and target_col in result_df.columns:\n",
    "                    target_mean = result_df.groupby(col)[target_col].mean()\n",
    "                    new_col = f\"{col}_target\"\n",
    "                    result_df[new_col] = result_df[col].map(target_mean)\n",
    "                    print(f\"✓ {col}: ターゲットエンコーディング完了 -> {new_col}\")\n",
    "                else:\n",
    "                    print(f\"❌ ターゲット列'{target_col}'が見つかりません。列'{col}'をスキップ\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {col}のエンコーディング中にエラーが発生しました: {e!s}\")\n",
    "\n",
    "    print(\"\\n=== エンコーディング完了 ===\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "dff = unified_encoding(dff)\n",
    "# dff = unified_encoding(dfff)\n",
    "\n",
    "print(dff.head())\n",
    "print(f\"\\n変換後のデータ形状: {dff.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多項式特徴量の生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 数値列を抽出\n",
    "    numeric_cols = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "    if len(numeric_cols) < 2:\n",
    "        print(\"多項式特徴量の生成には2つ以上の数値列が必要です\")\n",
    "        return df\n",
    "\n",
    "    print(\"\\n=== 数値列一覧 ===\")\n",
    "    for i, col in enumerate(numeric_cols, 1):\n",
    "        print(f\"{i}. {col}\")\n",
    "\n",
    "    print(\"\\n=== 数値列の統計情報 ===\")\n",
    "    print(df[numeric_cols].describe())\n",
    "\n",
    "    # 変換する列を選択\n",
    "    print(\"\\n=== 列の選択 ===\")\n",
    "    print(\"多項式特徴量に使用したい列名をカンマ区切りで入力してください（例: age,income,score）\")\n",
    "    print(\"全ての数値列を選択する場合は 'all' と入力してください\")\n",
    "    print(\"※注意: 列数が多いと特徴量数が爆発的に増加します\")\n",
    "\n",
    "    column_input = input(\"選択: \").strip()\n",
    "\n",
    "    if column_input.lower() == 'all':\n",
    "        selected_cols = numeric_cols\n",
    "    else:\n",
    "        try:\n",
    "            column_names = [x.strip() for x in column_input.split(',')]\n",
    "            selected_cols = [col for col in column_names if col in numeric_cols]\n",
    "            invalid_cols = [col for col in column_names if col not in numeric_cols]\n",
    "            if invalid_cols:\n",
    "                print(f\"警告: 以下の列名は数値列に存在しません: {', '.join(invalid_cols)}\")\n",
    "        except Exception:\n",
    "            print(\"無効な入力です。処理を終了します。\")\n",
    "            return df\n",
    "\n",
    "    if len(selected_cols) < 2:\n",
    "        print(\"2つ以上の有効な数値列が必要です\")\n",
    "        return df\n",
    "\n",
    "    print(f\"\\n選択された列: {', '.join(selected_cols)}\")\n",
    "\n",
    "    # 各列の詳細情報表示\n",
    "    print(\"\\n=== 選択列の詳細情報 ===\")\n",
    "    for col in selected_cols:\n",
    "        col_data = df[col].dropna()\n",
    "        print(f\"{col}: 範囲[{col_data.min():.2f}, {col_data.max():.2f}], 平均={col_data.mean():.2f}, 標準偏差={col_data.std():.2f}\")\n",
    "\n",
    "    # 予想される特徴量数を計算して表示\n",
    "    n_cols = len(selected_cols)\n",
    "    print(\"\\n=== 多項式特徴量設定 ===\")\n",
    "    print(\"次数による特徴量数の予想:\")\n",
    "    print(f\"1次: {n_cols}個 (元の特徴量)\")\n",
    "\n",
    "    import math\n",
    "    degree_2_count = n_cols + math.comb(n_cols, 2) + n_cols  # 1次 + 交互作用 + 2乗\n",
    "    degree_3_count = sum(math.comb(n_cols + r - 1, r) for r in range(1, 4))  # 1次〜3次の組み合わせ\n",
    "\n",
    "    print(f\"2次: 約{degree_2_count}個\")\n",
    "    if n_cols <= 5:  # 5列以下の場合のみ3次を表示\n",
    "        print(f\"3次: 約{degree_3_count}個\")\n",
    "\n",
    "    if n_cols > 5:\n",
    "        print(\"⚠️ 警告: 列数が多いため、2次までの使用を推奨します\")\n",
    "\n",
    "    # 次数の選択\n",
    "    while True:\n",
    "        try:\n",
    "            degree = int(input(\"多項式の次数を選択 (2または3): \").strip())\n",
    "            if degree in [2, 3]:\n",
    "                break\n",
    "            else:\n",
    "                print(\"2または3を入力してください\")\n",
    "        except ValueError:\n",
    "            print(\"数値を入力してください\")\n",
    "\n",
    "    # 交互作用のみかどうか\n",
    "    print(\"\\n多項式特徴量のタイプ:\")\n",
    "    print(\"1. full       - すべての項（x², xy, x³など）\")\n",
    "    print(\"2. interaction - 交互作用のみ（xy, xyzなど、単一変数の累乗は除く）\")\n",
    "\n",
    "    while True:\n",
    "        interaction_type = input(\"タイプを選択 (full/interaction): \").strip().lower()\n",
    "        if interaction_type in ['full', 'interaction']:\n",
    "            interaction_only = (interaction_type == 'interaction')\n",
    "            break\n",
    "        else:\n",
    "            print(\"fullまたはinteractionを入力してください\")\n",
    "\n",
    "    # バイアス項（定数項）の追加\n",
    "    while True:\n",
    "        bias_input = input(\"バイアス項（定数項）を追加しますか？ (y/n): \").strip().lower()\n",
    "        if bias_input in ['y', 'yes', 'n', 'no']:\n",
    "            include_bias = bias_input in ['y', 'yes']\n",
    "            break\n",
    "        else:\n",
    "            print(\"yまたはnを入力してください\")\n",
    "\n",
    "    # 多項式特徴量生成\n",
    "    print(\"\\n=== 多項式特徴量生成実行 ===\")\n",
    "\n",
    "    try:\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "        poly = PolynomialFeatures(\n",
    "            degree=degree,\n",
    "            interaction_only=interaction_only,\n",
    "            include_bias=include_bias\n",
    "        )\n",
    "\n",
    "        print(f\"設定: 次数={degree}, 交互作用のみ={interaction_only}, バイアス項={include_bias}\")\n",
    "\n",
    "        # 選択された列のみで多項式特徴量を生成\n",
    "        poly_features = poly.fit_transform(df[selected_cols])\n",
    "\n",
    "        # 特徴量名を生成\n",
    "        feature_names = poly.get_feature_names_out(selected_cols)\n",
    "\n",
    "        # 元の列を除いた新しい特徴量のみを取得\n",
    "        if not include_bias:\n",
    "            # 元の列（最初のn_cols個）を除く\n",
    "            new_features = poly_features[:, n_cols:]\n",
    "            new_feature_names = feature_names[n_cols:]\n",
    "        else:\n",
    "            # バイアス項があるので、最初の1個とその次のn_cols個を除く\n",
    "            new_features = poly_features[:, n_cols + 1:]\n",
    "            new_feature_names = feature_names[n_cols + 1:]\n",
    "\n",
    "            # バイアス項を別途追加\n",
    "            bias_features = poly_features[:, 0:1]\n",
    "            bias_names = feature_names[0:1]\n",
    "\n",
    "        # 新しい特徴量をDataFrameに変換\n",
    "        if len(new_feature_names) > 0:\n",
    "            new_poly_df = pd.DataFrame(new_features, columns=new_feature_names, index=df.index)\n",
    "            result_df = pd.concat([df, new_poly_df], axis=1)\n",
    "        else:\n",
    "            result_df = df.copy()\n",
    "\n",
    "        # バイアス項がある場合は追加\n",
    "        if include_bias:\n",
    "            bias_df = pd.DataFrame(bias_features, columns=bias_names, index=df.index)\n",
    "            result_df = pd.concat([result_df, bias_df], axis=1)\n",
    "\n",
    "        print(\"✓ 多項式特徴量生成完了\")\n",
    "        print(f\"✓ 元の列数: {len(selected_cols)}\")\n",
    "        print(f\"✓ 生成された新しい特徴量数: {len(feature_names) - len(selected_cols) - (1 if include_bias else 0)}\")\n",
    "        if include_bias:\n",
    "            print(\"✓ バイアス項: 1個\")\n",
    "        print(f\"✓ 総特徴量数: {len(feature_names)}\")\n",
    "\n",
    "        print(\"\\n生成された特徴量の例:\")\n",
    "        new_cols = [col for col in result_df.columns if col not in df.columns]\n",
    "        for col in new_cols[:5]:  # 最初の5個だけ表示\n",
    "            print(f\"  - {col}\")\n",
    "        if len(new_cols) > 5:\n",
    "            print(f\"  ... 他{len(new_cols) - 5}個\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 多項式特徴量生成中にエラーが発生しました: {e!s}\")\n",
    "        return df\n",
    "\n",
    "    print(\"\\n=== 多項式特徴量生成完了 ===\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "dff = polynomial_features(dff)\n",
    "# dff = polynomial_features(dfff)\n",
    "\n",
    "print(dff.head())\n",
    "print(f\"\\n変換後のデータ形状: {dff.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数dffをcsvファイルとして保存\n",
    "\n",
    "1. 保存したいcsvファイル名(.csv除く)を入力\n",
    "\n",
    "2. 00_pretreatment.ipynbと同一のディレクトリに保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, filename=None):\n",
    "\n",
    "    if filename is None:\n",
    "        filename = input(\"保存するファイル名を入力してください（.csvを除く）: \").strip()\n",
    "\n",
    "    # 入力が空の場合のデフォルト値\n",
    "    if not filename:\n",
    "        filename = \"output_data\"\n",
    "        print(f\"⚠ ファイル名が指定されなかったため、デフォルト名 '{filename}.csv' を使用します\")\n",
    "\n",
    "    if not filename.endswith('.csv'):\n",
    "        filename += '.csv'\n",
    "\n",
    "    try:\n",
    "        df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"✓ CSVファイル保存完了: {filename}\")\n",
    "        print(f\"  データ行数: {len(df)}\")\n",
    "        print(f\"  列数: {len(df.columns)}\")\n",
    "\n",
    "        # ファイルサイズを表示\n",
    "        import os\n",
    "        if os.path.exists(filename):\n",
    "            file_size = os.path.getsize(filename)\n",
    "            print(f\"  ファイルサイズ: {file_size:,} バイト\")\n",
    "\n",
    "        return filename\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ 保存エラー: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    saved_file = save_to_csv(dff)\n",
    "\n",
    "    if saved_file:\n",
    "        print(f\"\\n🎉 ファイルが正常に保存されました: {saved_file}\")\n",
    "    else:\n",
    "        print(\"\\n❌ ファイルの保存に失敗しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv保存後のdff,dfffを空にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dff' in globals():\n",
    "    del dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dff' in globals():\n",
    "    del dfff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一時確認用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    store_code store_name        date  time     sales  customer_count  \\\n",
      "0          191  横浜ベイクォーター  2023-05-01    10 -1.150414               0   \n",
      "1          191  横浜ベイクォーター  2023-05-01    11  0.355461              28   \n",
      "2          191  横浜ベイクォーター  2023-05-01    12  1.329690              46   \n",
      "3          191  横浜ベイクォーター  2023-05-01    13  0.354747              38   \n",
      "4          191  横浜ベイクォーター  2023-05-01    14 -0.219979              19   \n",
      "..         ...        ...         ...   ...       ...             ...   \n",
      "95         191  横浜ベイクォーター  2023-05-08    20 -1.150414               0   \n",
      "96         191  横浜ベイクォーター  2023-05-08    21 -0.975169               3   \n",
      "97         191  横浜ベイクォーター  2023-05-08    22 -1.150414               0   \n",
      "98         191  横浜ベイクォーター  2023-05-09    11 -0.206972              23   \n",
      "99         191  横浜ベイクォーター  2023-05-09    12 -0.085584              27   \n",
      "\n",
      "    party_count  sales_target  prev_year_same_weekday_sales  \\\n",
      "0             0          2000                          3219   \n",
      "1            14         74000                         76436   \n",
      "2            21         79000                         81592   \n",
      "3            22         82000                         84861   \n",
      "4            12         42000                         43987   \n",
      "..          ...           ...                           ...   \n",
      "95            0         21000                         12719   \n",
      "96            1          1000                          1510   \n",
      "97            0          3000                          2746   \n",
      "98           14         26000                         21585   \n",
      "99           19         77000                         61088   \n",
      "\n",
      "    prev_year_same_date_sales  dow  time_block_L  time_block_未使用  \n",
      "0                           0  Mon          True           False  \n",
      "1                      115318  Mon          True           False  \n",
      "2                       93527  Mon          True           False  \n",
      "3                       24049  Mon          True           False  \n",
      "4                       75467  Mon          True           False  \n",
      "..                        ...  ...           ...             ...  \n",
      "95                      26029  Mon         False           False  \n",
      "96                       3782  Mon         False           False  \n",
      "97                          0  Mon         False           False  \n",
      "98                      23867  Tue          True           False  \n",
      "99                      67038  Tue          True           False  \n",
      "\n",
      "[100 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(dff.head())\n",
    "except:\n",
    "    print(dfff.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
