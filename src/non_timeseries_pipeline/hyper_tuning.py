from collections.abc import Callable
from typing import Any

import optuna
import pandas as pd
from sklearn.model_selection import cross_val_score

from .mlflow_manager import MLflowManager


class OptunaHyperTuner:
    """Hyper parameter tuning using Optuna with nested cross validation and MLflow integration."""

    def __init__(
        self,
        estimator_factory: Callable[[], Any],
        param_ranges: dict[str, Any],
        outer_splits: int = 5,
        inner_splits: int = 3,
        n_trials: int = 50,
        scoring: str = "r2",
        random_state: int = 42,
        use_mlflow: bool = True,
        experiment_name: str = "hyperparameter_tuning",
        run_name: str | None = None,
        start_mlflow_run: bool = False,
    ) -> None:
        self.estimator_factory = estimator_factory
        self.param_ranges = param_ranges
        self.outer_splits = outer_splits
        self.inner_splits = inner_splits
        self.n_trials = n_trials
        self.scoring = scoring
        self.random_state = random_state
        self.use_mlflow = use_mlflow
        self.experiment_name = experiment_name
        self.run_name = run_name
        self.start_mlflow_run = start_mlflow_run
        self.mlflow_manager: MLflowManager | None = None
        if self.use_mlflow:
            self.mlflow_manager = MLflowManager(
                experiment_name=self.experiment_name,
                run_name=self.run_name,
                start_run=self.start_mlflow_run,
            )

    def _setup_mlflow(self) -> None:
        """Set up MLflow using :class:`MLflowManager`."""
        if self.mlflow_manager is None:
            return
        self.mlflow_manager.setup(
            outer_splits=self.outer_splits,
            inner_splits=self.inner_splits,
            n_trials=self.n_trials,
            scoring=self.scoring,
            random_state=self.random_state,
            param_ranges=self.param_ranges,
        )

    def _log_trial_results(self, trial: optuna.Trial, score: float, fold_idx: int | None = None) -> None:
        """Log each Optuna trial result (disabled)."""
        # MLflowã«ã¯æœ€çµ‚çµæœã®ã¿ã‚’è¨˜éŒ²ã™ã‚‹ãŸã‚ã€trialçµæœã®è¨˜éŒ²ã¯ç„¡åŠ¹åŒ–
        pass

    def _log_fold_results(self, fold_idx: int, score: float, best_params: dict) -> None:
        """Log each fold result (disabled)."""
        # MLflowã«ã¯æœ€çµ‚çµæœã®ã¿ã‚’è¨˜éŒ²ã™ã‚‹ãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰çµæœã®è¨˜éŒ²ã¯ç„¡åŠ¹åŒ–
        pass

    def _objective(
        self,
        trial: optuna.Trial,
        x_train: pd.DataFrame,
        y_train: pd.Series,
        fold_idx: int | None = None,
    ) -> float:
        """Objective function for Optuna using inner CV."""
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        params = {}
        for param_name, param_range in self.param_ranges.items():
            if isinstance(param_range, list):
                # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                params[param_name] = trial.suggest_categorical(param_name, param_range)
            elif isinstance(param_range, tuple) and len(param_range) == 2:
                # æ•°å€¤ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                if isinstance(param_range[0], int) and isinstance(param_range[1], int):
                    params[param_name] = trial.suggest_int(param_name, param_range[0], param_range[1])
                else:
                    params[param_name] = trial.suggest_float(param_name, param_range[0], param_range[1])
            else:
                raise ValueError(f"Unsupported parameter range format for {param_name}: {param_range}")

        # ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
        model = self.estimator_factory()
        model.set_params(**params)

        # å†…å´CVã§è©•ä¾¡

        scores = cross_val_score(
            model,
            x_train,
            y_train,
            cv=self.inner_splits,
            scoring=self.scoring,
            n_jobs=1,  # Optunaã§ã¯ä¸¦åˆ—å‡¦ç†ã‚’é¿ã‘ã‚‹
        )

        score = scores.mean()

        return score

    def tune(self, x: pd.DataFrame, y: pd.Series) -> dict[str, Any]:
        """Optunaã‚’ä½¿ç”¨ã—ã¦ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"""
        print("ğŸ”„ Optunaãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
        print(f"å¤–å´CVåˆ†å‰²æ•°: {self.outer_splits}")
        print(f"å†…å´CVåˆ†å‰²æ•°: {self.inner_splits}")
        print(f"è©¦è¡Œå›æ•°: {self.n_trials}")
        print("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¯„å›²:")
        for param, range_val in self.param_ranges.items():
            print(f"  - {param}: {range_val}")

        # MLflowã®è¨­å®š
        self._setup_mlflow()

        from sklearn.model_selection import KFold

        outer_cv = KFold(n_splits=self.outer_splits, shuffle=True, random_state=self.random_state)
        test_scores: list[float] = []
        best_params_list: list[dict[str, Any]] = []

        for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(x), 1):
            print(f"ğŸ”„ å¤–å´CV {fold_idx}/{self.outer_splits} å›ç›®ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
            x_train, x_test = x.iloc[train_idx], x.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            # Optunaã‚¹ã‚¿ãƒ‡ã‚£ã‚’ä½œæˆ
            study = optuna.create_study(
                direction="maximize" if self.scoring in ["r2", "accuracy"] else "minimize",
                sampler=optuna.samplers.TPESampler(seed=self.random_state),
            )

            # ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’å®Ÿè¡Œ
            study.optimize(
                lambda trial, x_train=x_train, y_train=y_train, fold_idx=fold_idx: self._objective(
                    trial,
                    x_train,
                    y_train,
                    fold_idx,
                ),
                n_trials=self.n_trials,
                show_progress_bar=False,
            )

            # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
            best_model = self.estimator_factory()
            best_model.set_params(**study.best_params)
            best_model.fit(x_train, y_train)

            # ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            score = best_model.score(x_test, y_test)
            test_scores.append(score)
            best_params_list.append(study.best_params)

            print(f"   âœ… å¤–å´CV {fold_idx} å›ç›®å®Œäº† - ã‚¹ã‚³ã‚¢: {score:.4f}")
            print(f"   ğŸ¯ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {study.best_params}")

        avg_score = sum(test_scores) / len(test_scores)
        std_score = pd.Series(test_scores).std()
        print(f"ğŸ”§ å¹³å‡ã‚¹ã‚³ã‚¢ ({self.scoring}): {avg_score:.4f}")
        print(f"ğŸ“Š ã‚¹ã‚³ã‚¢ã®æ¨™æº–åå·®: {std_score:.4f}")

        # æœ€ã‚‚è‰¯ã„ã‚¹ã‚³ã‚¢ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿”ã™
        best_fold_idx = test_scores.index(max(test_scores))
        best_params = best_params_list[best_fold_idx]

        # å…¨ãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
        print("ğŸš€ å…¨ãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
        final_model = self.estimator_factory()
        final_model.set_params(**best_params)
        final_model.fit(x, y)
        print("âœ… æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’å®Œäº†")

        if self.mlflow_manager is not None:
            self.mlflow_manager.log_results(
                best_params=best_params,
                avg_score=avg_score,
                std_score=std_score,
                test_scores=test_scores,
                final_model=final_model,
            )
            self.mlflow_manager.end_run()

        return {
            "best_params": best_params,
            "avg_score": avg_score,
            "std_score": std_score,
            "all_scores": test_scores,
            "all_params": best_params_list,
            "final_model": final_model,  # å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸæœ€çµ‚ãƒ¢ãƒ‡ãƒ«
            "mlflow_info": {
                "experiment_name": self.experiment_name,
                "run_name": self.run_name,
                "use_mlflow": self.use_mlflow,
            }
            if self.use_mlflow
            else None,
        }
