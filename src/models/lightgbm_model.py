"""
LightGBMã‚’ä½¿ç”¨ã—ãŸå›å¸°ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ã€‚

BaseModelã‚’ç¶™æ‰¿ã—ã¦LightGBMã®å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
"""

import pickle
from datetime import datetime
from pathlib import Path
from typing import Any

import lightgbm as lgb
import polars as pl

from .base import BaseModel


class LightGBMRegressor(BaseModel):
    """LightGBMã‚’ä½¿ç”¨ã—ãŸå›å¸°ãƒ¢ãƒ‡ãƒ«ã€‚"""

    _model: lgb.Booster

    def __init__(
        self,
        model_name: str | None = None,
        params: dict[str, Any] | None = None,
        num_boost_round: int = 100,
        early_stopping_rounds: int | None = None,
        verbose_eval: bool = False,
    ):
        """LightGBMRegressorã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚

        Args:
            model_name (str | None, optional): ãƒ¢ãƒ‡ãƒ«ã®åç§°. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ None.
            params (dict[str, Any] | None, optional): LightGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ None.
            num_boost_round (int, optional): ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°å›æ•°. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ 100.
            early_stopping_rounds (int | None, optional): æ—©æœŸåœæ­¢ã®ãƒ©ã‚¦ãƒ³ãƒ‰æ•°. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ None.
            verbose_eval (bool, optional): å­¦ç¿’éç¨‹ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ False.
        """
        super().__init__(model_name)

        default_params = {
            "objective": "regression",
            "metric": "rmse",
            "boosting_type": "gbdt",
            "num_leaves": 31,
            "learning_rate": 0.05,
            "feature_fraction": 0.9,
            "bagging_fraction": 0.8,
            "bagging_freq": 5,
            "verbose": -1,
            "random_state": 42,
        }

        if params:
            default_params.update(params)

        self.params = default_params
        self.num_boost_round = num_boost_round
        self.early_stopping_rounds = early_stopping_rounds
        self.verbose_eval = verbose_eval
        self._feature_names: list[str] | None = None
        # å­¦ç¿’æ™‚ã®æƒ…å ±ã‚’ä¿æŒã™ã‚‹ãŸã‚ã®å±æ€§
        self._training_info: dict[str, Any] = {}
        self._custom_comments: list[str] = []

    def train(self, features: pl.DataFrame, targets: pl.Series) -> None:
        """ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ã€‚

        Args:
            features (pl.DataFrame): ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿
            targets (pl.Series): æ­£è§£ãƒ‡ãƒ¼ã‚¿

        Raises:
            ValueError: ç‰¹å¾´é‡ã¾ãŸã¯ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒç©ºã®å ´åˆ
        """
        if features.is_empty():
            raise ValueError("ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

        if targets.is_empty():
            raise ValueError("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

        if features.shape[0] != len(targets):
            raise ValueError("ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®è¡Œæ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“")

        # ãƒ‡ãƒ¼ã‚¿å‹ã®æœ€çµ‚ãƒã‚§ãƒƒã‚¯
        print("\nğŸ” LightGBMç”¨ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯:")
        for col in features.columns:
            dtype = features[col].dtype
            if dtype == pl.Utf8:
                raise ValueError(f"æ–‡å­—åˆ—å‹ã®åˆ— '{col}' ãŒæ®‹ã£ã¦ã„ã¾ã™ã€‚æ•°å€¤å‹ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚")
            print(f"  {col}: {dtype}")

        self._feature_names = features.columns

        x = features.to_numpy()
        y = targets.to_numpy()

        train_data = lgb.Dataset(x, label=y, feature_name=self._feature_names)

        callbacks = []
        if self.verbose_eval:
            callbacks.append(lgb.log_evaluation(period=10))

        self._model = lgb.train(
            params=self.params,
            train_set=train_data,
            num_boost_round=self.num_boost_round,
            callbacks=callbacks if callbacks else None,
        )

        # å­¦ç¿’æ™‚ã®æƒ…å ±ã‚’è¨˜éŒ²
        self._training_info = {
            "data_size": len(features),
            "feature_count": len(features.columns),
            "training_timestamp": datetime.now().isoformat(),
            "num_boost_round": self.num_boost_round,
            "early_stopping_rounds": self.early_stopping_rounds,
            "best_iteration": self._model.best_iteration if hasattr(self._model, "best_iteration") else None,
            "best_score": self._model.best_score if hasattr(self._model, "best_score") else None,
        }

        self._is_trained = True

    def predict(self, features: pl.DataFrame) -> pl.Series:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹ã€‚

        Args:
            features (pl.DataFrame): ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿

        Returns:
            pl.Series: äºˆæ¸¬çµæœ

        Raises:
            RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ãªã„å ´åˆ
            ValueError: ç‰¹å¾´é‡ã®åˆ—æ•°ãŒå­¦ç¿’æ™‚ã¨ç•°ãªã‚‹å ´åˆ
        """
        if not self._is_trained:
            raise RuntimeError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«trainãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

        if features.is_empty():
            raise ValueError("ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

        if self._feature_names and len(features.columns) != len(self._feature_names):
            raise ValueError(
                f"ç‰¹å¾´é‡ã®åˆ—æ•°ãŒå­¦ç¿’æ™‚ã¨ç•°ãªã‚Šã¾ã™ã€‚æœŸå¾…å€¤: {len(self._feature_names)}, å®Ÿéš›: {len(features.columns)}"
            )

        x = features.to_numpy()

        predictions = self._model.predict(x)

        return pl.Series("predictions", predictions)

    def save_model(self, file_path: str | Path) -> None:
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã€‚

        Args:
            file_path (str | Path): ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Raises:
            RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ãªã„å ´åˆ
        """
        if not self._is_trained:
            raise RuntimeError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«trainãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

        file_path = Path(file_path)
        file_path.parent.mkdir(parents=True, exist_ok=True)

        model_data = {
            "model": self._model,
            "params": self.params,
            "feature_names": self._feature_names,
            "model_name": self.model_name,
            "training_info": self._training_info,
            "custom_comments": self._custom_comments,
        }

        with open(file_path, "wb") as f:
            pickle.dump(model_data, f)

    def load_model(self, file_path: str | Path) -> None:
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚

        Args:
            file_path (str | Path): èª­ã¿è¾¼ã¿å…ƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
            Exception: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
        """
        file_path = Path(file_path)

        if not file_path.exists():
            raise FileNotFoundError(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")

        try:
            with open(file_path, "rb") as f:
                model_data = pickle.load(f)

            self._model = model_data["model"]
            self.params = model_data["params"]
            self._feature_names = model_data["feature_names"]
            self.model_name = model_data["model_name"]
            self._training_info = model_data.get("training_info", {})
            self._custom_comments = model_data.get("custom_comments", [])
            self._is_trained = True

        except Exception as err:
            raise Exception("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ") from err

    def get_feature_importance(self) -> dict[str, float]:
        """ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—ã™ã‚‹ã€‚

        Returns:
            dict[str, float]: ç‰¹å¾´é‡åã¨é‡è¦åº¦ã®è¾æ›¸

        Raises:
            RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ãªã„å ´åˆ
        """
        if not self._is_trained:
            raise RuntimeError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«trainãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

        importance = self._model.feature_importance(importance_type="gain")

        if self._feature_names:
            return dict(zip(self._feature_names, importance, strict=False))
        else:
            return {f"feature_{i}": imp for i, imp in enumerate(importance)}

    def get_params(self) -> dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã€‚

        Returns:
            dict[str, Any]: ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        return self.params.copy()

    def get_training_info(self) -> dict[str, Any]:
        """å­¦ç¿’æ™‚ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã€‚

        Returns:
            dict[str, Any]: å­¦ç¿’æ™‚ã®æƒ…å ±
        """
        return self._training_info.copy()

    def print_training_info(self) -> None:
        """å­¦ç¿’æ™‚ã®æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
        if not self._is_trained:
            print("âš ï¸  ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return

        print("\nğŸ“Š å­¦ç¿’æ™‚ã®æƒ…å ±:")
        print(f"  ãƒ¢ãƒ‡ãƒ«å: {self.model_name}")
        print(f"  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {self._training_info.get('data_size', 'N/A')}")
        print(f"  ç‰¹å¾´é‡æ•°: {self._training_info.get('feature_count', 'N/A')}")
        print(f"  å­¦ç¿’æ—¥æ™‚: {self._training_info.get('training_timestamp', 'N/A')}")
        print(f"  ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°å›æ•°: {self._training_info.get('num_boost_round', 'N/A')}")
        print(f"  æ—©æœŸåœæ­¢å›æ•°: {self._training_info.get('early_stopping_rounds', 'N/A')}")
        print(f"  æœ€é©ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {self._training_info.get('best_iteration', 'N/A')}")

        best_score = self._training_info.get("best_score", {})
        if best_score:
            print("  æœ€é©ã‚¹ã‚³ã‚¢:")
            for metric, value in best_score.items():
                print(f"    {metric}: {value}")

        if self._custom_comments:
            print("  ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ¡ãƒ³ãƒˆ:")
            for i, comment in enumerate(self._custom_comments, 1):
                print(f"    {i}. {comment}")

    def add_comment(self, comment: str) -> None:
        """ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã™ã‚‹ã€‚

        Args:
            comment (str): è¿½åŠ ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ
        """
        self._custom_comments.append(comment)

    def get_comments(self) -> list[str]:
        """ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã™ã‚‹ã€‚

        Returns:
            list[str]: ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        return self._custom_comments.copy()
