"""
éæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å®Ÿè¡Œä¾‹:
python src/scripts_model/01_model_non_time_series.py \
    --db-path data/database.sqlite \
    --table-name sales_data \
    --target-column sales \
    --outerCV-splits 5 \
    --use-mlflow \
    --experiment-name sales_prediction

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
    --db-path: SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    --table-name: èª­ã¿è¾¼ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«å
    --target-column: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—å
    --outerCV-splits: å¤–å´ã®CVåˆ†å‰²æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
    --use-mlflow: MLflowã‚’ä½¿ç”¨ã™ã‚‹
    --no-mlflow: MLflowã‚’ä½¿ç”¨ã—ãªã„
    --no-tuning: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹
    --experiment-name: MLflowã®å®Ÿé¨“åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: non_timeseries_pipelineï¼‰
    --run-name: MLflowå®Ÿè¡Œå
    --mlflow-tracking-uri: MLflowãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°URIï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: sqlite:///mlflow.dbï¼‰
"""

import argparse
import sys
from pathlib import Path
from datetime import datetime
import json
import joblib

import mlflow
import pandas as pd
import polars as pl
from lightgbm import LGBMRegressor
from sklearn.model_selection import train_test_split

# ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤‰æ›´
sys.path.append(str(Path(__file__).parent.parent.parent))
from src.data.handlers.sqlite_handler import SQLiteHandler
from src.non_timeseries_pipeline.feature_manager import FeatureManager
from src.non_timeseries_pipeline.hyper_tuning import OptunaHyperTuner
from src.non_timeseries_pipeline.pipeline import TreeModelPipeline
from src.non_timeseries_pipeline.target_manager import TargetManager

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

ARTIFACT_DIR = Path("artifacts")
ARTIFACT_DIR.mkdir(exist_ok=True)

# æ—¢å­˜ã®åˆ—ã‚’ç‰¹å¾´é‡ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ãƒªã‚¹ãƒˆ
FEATURE_COLUMNS = [
    "date_and_time",
    "dow_flag",
    "prev_year_same_weekday_sales_daily_sum",
    "time_flag",
    "Yokohama_Temperature",
    "is_weekend",
    "sales_trailing_ma_3",
    "sales_trailing_ma_14",
    "holiday",
]


# feature_engineeringé–¢æ•°ã§ä½œæˆã™ã‚‹ç‰¹å¾´é‡ã®åå‰
ENGINEERED_FEATURES = [
]

def feature_engineering(data: pl.DataFrame) -> pl.DataFrame:
    """ä¸€éƒ¨ã®åˆ—ã‚’å¤‰æ›ã—ã€æ–°ãŸãªç‰¹å¾´é‡åˆ—ã‚’è¿”ã™"""
    df = data.clone()

    # æ—¥ä»˜ã‚’datetimeå‹ã«å¤‰æ›
    df = df.with_columns(pl.col("date_and_time").str.to_datetime("%Y-%m-%d %H:%M:%S").alias("datetime"))

    # æ–°ã—ã„ç‰¹å¾´é‡ã‚’ä½œæˆ
    engineered = df.with_columns(
        [
            # pl.when(pl.col("time").is_in([11, 12, 13])).then(1).otherwise(0).alias("is_lunch"),
            # pl.col("datetime").dt.weekday().alias("weekday"),
            # pl.when(pl.col("time") < 12)
            # .then(0)
            # .when(pl.col("time") < 15)
            # .then(1)
            # .when(pl.col("time") < 18)
            # .then(2)
            # .otherwise(3)
            # .alias("time_category"),
            # pl.when(pl.col("date_month").is_in([12, 1, 2]))
            # .then(0)
            # .when(pl.col("date_month").is_in([3, 4, 5]))
            # .then(1)
            # .when(pl.col("date_month").is_in([6, 7, 8]))
            # .then(2)
            # .otherwise(3)
            # .alias("season"),
        ]
    )

    return engineered.select(ENGINEERED_FEATURES)

def setup_mlflow(args) -> bool:
    """MLflow ã®è¨­å®šã‚’è¡Œã„ã€å¿…è¦ãªã‚‰ run ã‚’é–‹å§‹ã™ã‚‹"""
    use_mlflow = args.use_mlflow or not args.no_mlflow
    if use_mlflow:
        mlflow.set_tracking_uri(args.mlflow_tracking_uri)
        mlflow.set_experiment(args.experiment_name)
        if not args.run_name:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            args.run_name = f"non_timeseries_{args.table_name}_{timestamp}"
        mlflow.start_run(run_name=args.run_name)
        mlflow.log_params({
            "db_path": args.db_path,
            "table_name": args.table_name,
            "target_column": args.target_column,
            "outerCV_splits": args.outerCV_splits,
            "model_type": "LightGBM",
            "pipeline_type": "non_timeseries",
        })
    return use_mlflow

def log_data_info(use_mlflow: bool, df: pd.DataFrame, feature_columns: int) -> None:
    """ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’MLflowã«è¨˜éŒ²"""
    if use_mlflow:
        mlflow.log_params({
            "data_rows": len(df),
            "data_columns": len(df.columns),
            "feature_columns": feature_columns,
        })

def log_tuning_results(use_mlflow: bool, best_params: dict, avg_score: float, std_score: float, all_scores: list) -> None:
    """ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’MLflowã«è¨˜éŒ²"""
    if use_mlflow:
        mlflow.log_metrics({
            "tuning_avg_score": avg_score,
            "tuning_std_score": std_score,
            "tuning_best_score": max(all_scores),
            "tuning_worst_score": min(all_scores),
        })
        for name, val in best_params.items():
            mlflow.log_param(f"best_{name}", val)

def log_final_metrics(use_mlflow: bool, train_metrics: dict, test_metrics: dict) -> None:
    """æœ€çµ‚è©•ä¾¡æŒ‡æ¨™ã‚’MLflowã«è¨˜éŒ²"""
    if use_mlflow:
        mlflow.log_metrics({
            "train_r2":    train_metrics["r2"],
            "train_mae":   train_metrics["mae"],
            "train_mse":   train_metrics["mse"],
            "train_rmse":  train_metrics["rmse"],
            "test_r2":     test_metrics["r2"],
            "test_mae":    test_metrics["mae"],
            "test_mse":    test_metrics["mse"],
            "test_rmse":   test_metrics["rmse"],
        })

def log_feature_importance(use_mlflow: bool, feature_names: list, importances: list) -> None:
    """ç‰¹å¾´é‡é‡è¦åº¦ã‚’MLflowã«è¨˜éŒ²"""
    if use_mlflow:
        for name, imp in zip(feature_names, importances, strict=True):
            mlflow.log_metric(f"feature_importance_{name}", imp)

def main():
    parser = argparse.ArgumentParser(description="éæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã™")
    parser.add_argument("--db-path",      type=str, required=True,  help="SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--table-name",   type=str, required=True,  help="èª­ã¿è¾¼ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«å")
    parser.add_argument("--target-column",type=str, required=True,  help="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—å")
    parser.add_argument("--outerCV-splits",type=int, default=5,    help="å¤–å´ã®CVåˆ†å‰²æ•°")
    parser.add_argument("--use-mlflow",   action="store_true",     help="MLflowã‚’ä½¿ç”¨ã™ã‚‹")
    parser.add_argument("--no-mlflow",    action="store_true",     help="MLflowã‚’ä½¿ç”¨ã—ãªã„")
    parser.add_argument("--no-tuning",    action="store_true",     help="ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹")
    parser.add_argument("--experiment-name", type=str, default="non_timeseries_pipeline", help="MLflowã®å®Ÿé¨“å")
    parser.add_argument("--run-name",        type=str, help="MLflowå®Ÿè¡Œå")
    parser.add_argument("--mlflow-tracking-uri", type=str, default="sqlite:///mlflow.db", help="MLflowãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°URI")
    args = parser.parse_args()

    # MLflowè¨­å®š
    use_mlflow = setup_mlflow(args)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    db_path = Path(args.db_path)
    if not db_path.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        sys.exit(1)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with SQLiteHandler(db_path) as handler:
        if not handler.table_exists(args.table_name):
            print(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ« '{args.table_name}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            sys.exit(1)
        cols = [col[1] for col in handler.get_table_info(args.table_name)]
        rows = handler.fetch_all(f"SELECT * FROM {args.table_name}")
    df = pd.DataFrame(rows, columns=cols)
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­è¾¼å®Œäº†: {len(df)} è¡Œ, {len(df.columns)} åˆ—")

    # æŒ‡å®šã•ã‚ŒãŸç‰¹å¾´é‡ã®ã¿ã‚’é¸æŠ
    available_features = [col for col in FEATURE_COLUMNS if col in df.columns]
    missing_features = [col for col in FEATURE_COLUMNS if col not in df.columns]
    
    if missing_features:
        print(f"âš ï¸ æŒ‡å®šã•ã‚ŒãŸç‰¹å¾´é‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_features}")
    
    print(f"ğŸ“Š ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡: {available_features}")
    
    # æŒ‡å®šã•ã‚ŒãŸç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã®ã¿ã‚’é¸æŠ
    selected_columns = available_features + [args.target_column]
    df_selected = df[selected_columns].copy()
    
    print("ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
    df_pl = pl.from_pandas(df_selected)
    engineered_features = feature_engineering(df_pl)
    engineered_features_pd = engineered_features.to_pandas()
    
    X_raw = pd.concat([df_selected[available_features], engineered_features_pd], axis=1)
    y_raw = df_selected[args.target_column]
    
    print(f"âœ… ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†: {len(X_raw.columns)} åˆ—")
    print(f"   å…ƒã®ç‰¹å¾´é‡: {len(available_features)} åˆ—")
    print(f"   ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ç‰¹å¾´é‡: {len(ENGINEERED_FEATURES)} åˆ—")

    # å‰å‡¦ç†
    fm = FeatureManager()
    tm = TargetManager()
    X_all = fm.transform(X_raw)
    y_all = tm.transform(y_raw)

    # â”€â”€ â‘  ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆç”¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚’åˆ‡ã‚Šå‡ºã™ â”€â”€
    X_dev, X_test, y_dev, y_test = train_test_split(
        X_all, y_all, test_size=0.2, random_state=42
    )
    log_data_info(use_mlflow, X_dev, feature_columns=len(X_dev.columns))

    # ãƒ¢ãƒ‡ãƒ«å®šç¾©
    def estimator_factory() -> LGBMRegressor:
        return LGBMRegressor(
            random_state=42,
            verbose=-1,
            force_col_wise=True,
            min_child_samples=5,
            min_split_gain=0.0,
        )

    default_param_ranges = {
        "n_estimators":       (50, 200),
        "max_depth":          (3,  10),
        "learning_rate":      (0.01, 0.3),
        "min_child_samples":  (5, 20),
        "subsample":          (0.7, 1.0),
        "colsample_bytree":   (0.7, 1.0),
        "reg_alpha":          (0.0, 1.0),
        "reg_lambda":         (0.0, 1.0),
    }

    # ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° or ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå­¦ç¿’
    if args.no_tuning:
        print("â­ï¸ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        model = estimator_factory()
        model.fit(X_dev, y_dev)
        best_params = model.get_params()
        if use_mlflow:
            mlflow.log_param("tuning_skipped", True)
    else:
        print("ğŸ”§ ãƒã‚¹ãƒˆCV + Optunaã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")
        tuner = OptunaHyperTuner(
            estimator_factory,
            default_param_ranges,
            outer_splits=args.outerCV_splits,
            inner_splits=3,
            n_trials=50,
            use_mlflow=use_mlflow,
            experiment_name=args.experiment_name,
            run_name=args.run_name,
            start_mlflow_run=False,
        )
        tune_res = tuner.tune(X_dev, y_dev)
        model       = tune_res["final_model"]
        best_params = tune_res["best_params"]
        avg_score   = tune_res["avg_score"]
        std_score   = tune_res["std_score"]
        all_scores  = tune_res["all_scores"]
        log_tuning_results(use_mlflow, best_params, avg_score, std_score, all_scores)

    # â”€â”€ â‘¡ é–‹ç™ºç”¨ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã§å†å­¦ç¿’ â”€â”€
    model.fit(X_dev, y_dev)

    # â”€â”€ â‘¢ ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆãƒ†ã‚¹ãƒˆã§è©•ä¾¡ â”€â”€
    # Dev
    y_dev_pred = model.predict(X_dev)
    train_m = {
        "r2":   r2_score(y_dev, y_dev_pred),
        "mae":  mean_absolute_error(y_dev, y_dev_pred),
        "mse":  mean_squared_error(y_dev, y_dev_pred),
        "rmse": mean_squared_error(y_dev, y_dev_pred) ** 0.5,
    }
    # Test
    y_test_pred = model.predict(X_test)
    test_m = {
        "r2":   r2_score(y_test, y_test_pred),
        "mae":  mean_absolute_error(y_test, y_test_pred),
        "mse":  mean_squared_error(y_test, y_test_pred),
        "rmse": mean_squared_error(y_test, y_test_pred) ** 0.5,
    }

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    print("\nğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©•ä¾¡:")
    print(f"   RÂ²:   {train_m['r2']:.4f}, MAE: {train_m['mae']:.2f}, MSE: {train_m['mse']:.2f}, RMSE: {train_m['rmse']:.2f}")
    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è©•ä¾¡:")
    print(f"   RÂ²:   {test_m['r2']:.4f}, MAE: {test_m['mae']:.2f}, MSE: {test_m['mse']:.2f}, RMSE: {test_m['rmse']:.2f}")

    log_final_metrics(use_mlflow, train_m, test_m)

    # ç‰¹å¾´é‡é‡è¦åº¦
    fi = getattr(model, "feature_importances_", None)
    if fi is not None:
        names = X_dev.columns.tolist()
        pairs = sorted(zip(names, fi), key=lambda x: x[1], reverse=True)[:10]
        print("\nğŸ¯ ç‰¹å¾´é‡é‡è¦åº¦ (ä¸Šä½10ä»¶):")
        for i, (n, v) in enumerate(pairs, 1):
            print(f"   {i:2d}. {n:<30} {v:.4f}")
        log_feature_importance(use_mlflow, names, fi)

    # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜
    joblib.dump(fm, ARTIFACT_DIR/"feature_manager.pkl")
    joblib.dump(tm, ARTIFACT_DIR/"target_manager.pkl")
    joblib.dump(model, ARTIFACT_DIR/"model.pkl")

    metadata = {
        "feature_columns":     X_dev.columns.tolist(),
        "original_features":   available_features,
        "engineered_features": ENGINEERED_FEATURES,
        "categorical_columns": fm.categorical_columns,
        "date_columns":        fm.date_columns,
        "best_params":         best_params,
        "run_datetime":        datetime.now().isoformat()
    }
    with open(ARTIFACT_DIR/"metadata.json", "w") as f:
        json.dump(metadata, f, indent=2)

    # MLflow run çµ‚äº†
    if use_mlflow:
        mlflow.end_run()

if __name__ == "__main__":
    main()
