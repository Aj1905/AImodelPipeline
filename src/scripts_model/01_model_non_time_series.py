#!/usr/bin/env python3
"""
éæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ä¾‹:
# åŸºæœ¬çš„ãªå®Ÿè¡Œ(MLflowæœ‰åŠ¹ã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æœ‰åŠ¹)
python src/scripts_model/01_model_non_time_series.py \
    --db-path data/database.sqlite \
    --table-name mores_all \
    --target-column sales \
    --outerCV-splits 5

# ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹å ´åˆ
python src/scripts_model/01_model_non_time_series.py \
    --db-path data/database.sqlite \
    --table-name mores_all \
    --target-column sales \
    --outerCV-splits 5 \
    --no-tuning

# MLflowã‚’ç„¡åŠ¹ã«ã™ã‚‹å ´åˆ
python src/scripts_model/01_model_non_time_series.py \
    --db-path data/database.sqlite \
    --table-name mores_all \
    --target-column sales \
    --outerCV-splits 5 \
    --no-mlflow

# ã‚«ã‚¹ã‚¿ãƒ å®Ÿé¨“åã‚’æŒ‡å®š
python src/scripts_model/01_model_non_time_series.py \
    --db-path data/database.sqlite \
    --table-name mores_all \
    --target-column sales \
    --outerCV-splits 5 \
    --experiment-name "restaurant_sales_forecast"

# ã‚«ã‚¹ã‚¿ãƒ å®Ÿè¡Œåã‚’æŒ‡å®š
python src/scripts_model/01_model_non_time_series.py \
    --db-path data/database.sqlite \
    --table-name mores_all \
    --target-column sales \
    --outerCV-splits 5 \
    --run-name "experiment_v1"

# MLflow UIã§çµæœã‚’ç¢ºèª
./start_mlflow_ui.sh
# ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:5000 ã«ã‚¢ã‚¯ã‚»ã‚¹
"""

import argparse
import sys
from datetime import datetime
from pathlib import Path

import joblib
import mlflow
import pandas as pd
from lightgbm import LGBMRegressor

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.data.handlers.sqlite_handler import SQLiteHandler
from src.non_timeseries_pipeline.feature_manager import FeatureManager
from src.non_timeseries_pipeline.hyper_tuning import OptunaHyperTuner
from src.non_timeseries_pipeline.pipeline import TreeModelPipeline
from src.non_timeseries_pipeline.target_manager import TargetManager

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FEATURE_COLUMNS = [
    "date_and_time",
    "date_year",
    "date_month",
    "date_day",
    "time",
    "dow",
    "holiday",
    "is_lunch",
    "is_dinner",
    "is_month_end",
    "is_weekend",
    "prev_year_same_weekday_sales_daily_sum",
]


# feature_engineeringé–¢æ•°: ãƒ†ãƒ¼ãƒ–ãƒ«å¤‰æ•°ã‚’å¤‰æ›ã—ã€æ–°ãŸãªç‰¹å¾´é‡ã‚’ä½œæˆ
def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:
    """
    å¿…è¦ãªå¤‰æ›ã‚’è¡Œã„ã€æ–°ã—ã„ç‰¹å¾´é‡ã‚’å«ã‚€DataFrameã‚’è¿”ã—ã¾ã™
    """
    df = df.copy()
    # æ—¥ä»˜æ–‡å­—åˆ— â†’ datetime
    df["datetime"] = pd.to_datetime(df["date_and_time"], format="%Y-%m-%d %H:%M:%S")

    # ãƒ©ãƒ³ãƒæ™‚é–“ãƒ•ãƒ©ã‚°(11-13æ™‚)
    df["is_lunch"] = df["time"].isin([11, 12, 13]).astype(int)

    # æ›œæ—¥(0=æœˆæ›œ)
    df["weekday"] = df["datetime"].dt.weekday

    # æ™‚é–“å¸¯ã‚«ãƒ†ã‚´ãƒª(0=<12æ™‚, 1=<15æ™‚, 2=<18æ™‚, 3=ãã‚Œä»¥å¤–)
    df["time_category"] = df["time"].apply(lambda x: 0 if x < 12 else (1 if x < 15 else (2 if x < 18 else 3)))

    # å­£ç¯€(0=å†¬,1=æ˜¥,2=å¤,3=ç§‹)
    df["season"] = df["datetime"].dt.month.apply(
        lambda m: 0 if m in [12, 1, 2] else (1 if m in [3, 4, 5] else (2 if m in [6, 7, 8] else 3))
    )

    return df[["is_lunch", "weekday", "time_category", "season"]]


ENGINEERED_FEATURES = ["is_lunch"]
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def setup_mlflow(args) -> bool:
    """MLflowã®è¨­å®šã‚’è¡Œã†"""
    use_mlflow = args.use_mlflow or not args.no_mlflow
    if use_mlflow:
        mlflow.set_tracking_uri(args.mlflow_tracking_uri)
        mlflow.set_experiment(args.experiment_name)

        if not args.run_name:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            args.run_name = f"non_timeseries_{args.table_name}_{timestamp}"

        mlflow.start_run(run_name=args.run_name)

        # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
        mlflow.log_params(
            {
                "db_path": args.db_path,
                "table_name": args.table_name,
                "target_column": args.target_column,
                "outerCV_splits": args.outerCV_splits,
                "model_type": "LightGBM",
                "pipeline_type": "non_timeseries",
            }
        )
    return use_mlflow


def log_data_info(use_mlflow: bool, df: pd.DataFrame) -> None:
    """ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’MLflowã«è¨˜éŒ²"""
    if use_mlflow:
        mlflow.log_params(
            {
                "data_rows": len(df),
                "data_columns": len(df.columns),
                "feature_columns": len(FEATURE_COLUMNS),
            }
        )


def log_tuning_results(
    use_mlflow: bool, best_params: dict, avg_score: float, std_score: float, all_scores: list
) -> None:
    """ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’MLflowã«è¨˜éŒ²"""
    if use_mlflow:
        mlflow.log_metrics(
            {
                "tuning_avg_score": avg_score,
                "tuning_std_score": std_score,
                "tuning_best_score": max(all_scores),
                "tuning_worst_score": min(all_scores),
            }
        )

        # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
        for param_name, param_value in best_params.items():
            mlflow.log_param(f"best_{param_name}", param_value)


def log_final_metrics(use_mlflow: bool, train_metrics: dict, test_metrics: dict) -> None:
    """æœ€çµ‚è©•ä¾¡æŒ‡æ¨™ã‚’MLflowã«è¨˜éŒ²"""
    if use_mlflow:
        mlflow.log_metrics(
            {
                "train_r2": train_metrics["r2"],
                "train_mae": train_metrics["mae"],
                "train_mse": train_metrics["mse"],
                "train_rmse": train_metrics["rmse"],
                "test_r2": test_metrics["r2"],
                "test_mae": test_metrics["mae"],
                "test_mse": test_metrics["mse"],
                "test_rmse": test_metrics["rmse"],
            }
        )


def log_feature_importance(use_mlflow: bool, feature_names: list, feature_importance: list) -> None:
    """ç‰¹å¾´é‡é‡è¦åº¦ã‚’MLflowã«è¨˜éŒ²"""
    if use_mlflow:
        for feature_name, importance in zip(feature_names, feature_importance, strict=True):
            mlflow.log_metric(f"feature_importance_{feature_name}", importance)


def log_overfitting_analysis(use_mlflow: bool, overfitting: dict) -> None:
    """éå­¦ç¿’åˆ†æã‚’MLflowã«è¨˜éŒ²"""
    if use_mlflow:
        mlflow.log_metrics(
            {
                "overfitting_r2_difference": overfitting["r2_difference"],
                "overfitting_rmse_difference": overfitting["rmse_difference"],
            }
        )
        mlflow.set_tag("is_overfitting", str(overfitting["is_overfitting"]))


def save_final_model(use_mlflow: bool, pipeline, experiment_name: str, run_name: str) -> None:
    """æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’MLflowã«ä¿å­˜"""
    if use_mlflow:
        # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜
        model_path = "final_pipeline_model.pkl"
        joblib.dump(pipeline, model_path)
        mlflow.log_artifact(model_path, "pipeline_model")

        # MLflowã®å®Ÿè¡Œã‚’çµ‚äº†
        mlflow.end_run()
        print(f"\nğŸ“Š MLflowã«çµæœã‚’è¨˜éŒ²ã—ã¾ã—ãŸ - å®Ÿé¨“å: {experiment_name}, å®Ÿè¡Œå: {run_name}")


def main() -> None:  # noqa: C901
    parser = argparse.ArgumentParser(description="éæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™")
    parser.add_argument("--db-path", type=str, required=True, help="SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--table-name", type=str, required=True, help="èª­ã¿è¾¼ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«å")
    parser.add_argument("--target-column", type=str, required=True, help="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—å")
    parser.add_argument("--outerCV-splits", type=int, default=5, help="å¤–å´ã®ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†å‰²æ•°")
    parser.add_argument("--use-mlflow", action="store_true", help="MLflowã‚’ä½¿ç”¨ã™ã‚‹")
    parser.add_argument("--no-mlflow", action="store_true", help="MLflowã‚’ä½¿ç”¨ã—ãªã„")
    parser.add_argument("--no-tuning", action="store_true", help="ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹")
    parser.add_argument("--experiment-name", type=str, default="non_timeseries_pipeline", help="MLflowã®å®Ÿé¨“å")
    parser.add_argument("--run-name", type=str, help="MLflowã®å®Ÿè¡Œå")
    parser.add_argument(
        "--mlflow-tracking-uri", type=str, default="sqlite:///mlflow.db", help="MLflowã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°URI"
    )
    args = parser.parse_args()

    # MLflowã®è¨­å®š
    use_mlflow = setup_mlflow(args)

    db_path = Path(args.db_path)
    if not db_path.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        sys.exit(1)

    with SQLiteHandler(db_path) as handler:
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
        if not handler.table_exists(args.table_name):
            print(f"âŒ ãƒ†ãƒ¼ãƒ–ãƒ« '{args.table_name}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            # åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
            tables_query = "SELECT name FROM sqlite_master WHERE type='table'"
            tables = handler.fetch_all(tables_query)
            if tables:
                print("åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«:")
                for table in tables:
                    print(f"  - {table[0]}")
            sys.exit(1)

        # ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆ—æƒ…å ±ã‚’å–å¾—
        table_info = handler.get_table_info(args.table_name)
        columns = [col[1] for col in table_info]

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã®å­˜åœ¨ç¢ºèª
        if args.target_column not in columns:
            print(f"âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ— '{args.target_column}' ãŒãƒ†ãƒ¼ãƒ–ãƒ«ã«å­˜åœ¨ã—ã¾ã›ã‚“")
            print(f"åˆ©ç”¨å¯èƒ½ãªåˆ—: {', '.join(columns)}")
            sys.exit(1)

        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        query = f"SELECT * FROM {args.table_name}"
        results = handler.fetch_all(query)
        df = pd.DataFrame(results, columns=columns)

    print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {args.table_name}")
    print(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—: {args.target_column}")

    # MLflowã«ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¨˜éŒ²
    log_data_info(use_mlflow, df)

    feature_manager = FeatureManager()
    target_manager = TargetManager()

    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’åˆ†é›¢
    x_raw = df.drop(columns=[args.target_column])
    y_raw = df[args.target_column]

    # å‰å‡¦ç†ã‚’å®Ÿè¡Œ
    x = feature_manager.transform(x_raw)
    y = target_manager.transform(y_raw)

    def estimator_factory() -> LGBMRegressor:
        """LightGBMãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•° - è­¦å‘Šã‚’æŠ‘åˆ¶ã™ã‚‹è¨­å®š"""
        return LGBMRegressor(
            random_state=42,
            verbose=-1,  # è­¦å‘Šã‚’æŠ‘åˆ¶
            force_col_wise=True,  # åˆ—æ–¹å‘ã®å‡¦ç†ã‚’å¼·åˆ¶
            min_child_samples=5,  # æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¨­å®š
            min_split_gain=0.0,  # åˆ†å‰²ã‚²ã‚¤ãƒ³ã®æœ€å°å€¤ã‚’0ã«è¨­å®š
        )

    # ã‚ˆã‚Šé©åˆ‡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¯„å›²(Optunaç”¨)
    param_ranges = {
        "n_estimators": (50, 200),  # æ•´æ•°ç¯„å›²
        "max_depth": (3, 10),  # æ•´æ•°ç¯„å›²
        "learning_rate": (0.01, 0.3),  # æµ®å‹•å°æ•°ç‚¹ç¯„å›²
        "min_child_samples": (5, 20),  # æ•´æ•°ç¯„å›²
        "subsample": (0.7, 1.0),  # æµ®å‹•å°æ•°ç‚¹ç¯„å›²
        "colsample_bytree": (0.7, 1.0),  # æµ®å‹•å°æ•°ç‚¹ç¯„å›²
        "reg_alpha": (0.0, 1.0),  # L1æ­£å‰‡åŒ–
        "reg_lambda": (0.0, 1.0),  # L2æ­£å‰‡åŒ–
    }

    if args.no_tuning:
        print("\nâ­ï¸  ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        print("ğŸ“‹ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
        model = estimator_factory()

        # ãƒã‚¹ãƒˆCVã§è©•ä¾¡(ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—)
        from sklearn.model_selection import cross_val_score

        scores = cross_val_score(model, x, y, cv=args.outerCV_splits, scoring="r2")

        avg_score = scores.mean()
        std_score = scores.std()
        all_scores = scores.tolist()

        print("\nğŸ“Š ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®è©•ä¾¡çµæœ:")
        print(f"å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.4f}")
        print(f"ã‚¹ã‚³ã‚¢ã®æ¨™æº–åå·®: {std_score:.4f}")
        print(f"å„ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã®ã‚¹ã‚³ã‚¢: {[f'{score:.4f}' for score in all_scores]}")

        # å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
        model.fit(x, y)
        final_model = model

        # MLflowã«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’è¨˜éŒ²(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
        if use_mlflow:
            mlflow.log_params(
                {
                    "tuning_skipped": True,
                    "default_n_estimators": model.n_estimators,
                    "default_max_depth": model.max_depth,
                    "default_learning_rate": model.learning_rate,
                }
            )

    else:
        print("\nğŸ”§ ãƒã‚¹ãƒˆCV + Optunaãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")
        print("ğŸ“‹ æ‰‹æ³•: å¤–å´CVã§ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ + å†…å´CVã§ãƒ™ã‚¤ã‚ºæœ€é©åŒ–")
        print(f"å¤–å´CVåˆ†å‰²æ•°: {args.outerCV_splits}")
        print("å†…å´CVåˆ†å‰²æ•°: 3")
        print("ãƒ™ã‚¤ã‚ºæœ€é©åŒ–è©¦è¡Œå›æ•°: 50")
        print("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¯„å›²:")
        for param, range_val in param_ranges.items():
            print(f"  - {param}: {range_val}")

        tuner = OptunaHyperTuner(
            estimator_factory,
            param_ranges,
            outer_splits=args.outerCV_splits,
            inner_splits=3,
            n_trials=50,
            use_mlflow=use_mlflow,
            experiment_name=args.experiment_name,
            run_name=args.run_name,
            start_mlflow_run=False,  # æ—¢å­˜ã®MLflowå®Ÿè¡Œã‚’ä½¿ç”¨
        )
        tune_result = tuner.tune(x, y)

        best_params = tune_result["best_params"]
        avg_score = tune_result["avg_score"]
        std_score = tune_result["std_score"]
        all_scores = tune_result["all_scores"]
        final_model = tune_result["final_model"]

        print(f"\nğŸ† æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {best_params}")
        print(f"ğŸ“Š å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.4f}")
        print(f"ğŸ“ˆ ã‚¹ã‚³ã‚¢ã®æ¨™æº–åå·®: {std_score:.4f}")
        print(f"ğŸ“ˆ å„ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã®ã‚¹ã‚³ã‚¢: {[f'{score:.4f}' for score in all_scores]}")

        # MLflowã«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’è¨˜éŒ²
        log_tuning_results(use_mlflow, best_params, avg_score, std_score, all_scores)

    # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ(final_modelã¯æ—¢ã«å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’æ¸ˆã¿)
    model = final_model

    pipeline = TreeModelPipeline(model=model, feature_manager=feature_manager, target_manager=target_manager)
    results = pipeline.train(test_size=0.1, random_state=42)

    # çµæœã‚’è©³ç´°ã«è¡¨ç¤º
    print("\nğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡æŒ‡æ¨™:")
    train_metrics = results["train_metrics"]
    print(f"   RÂ²: {train_metrics['r2']:.4f}")
    print(f"   MAE: {train_metrics['mae']:.2f}")
    print(f"   MSE: {train_metrics['mse']:.2f}")
    print(f"   RMSE: {train_metrics['rmse']:.2f}")

    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡æŒ‡æ¨™:")
    test_metrics = results["test_metrics"]
    print(f"   RÂ²: {test_metrics['r2']:.4f}")
    print(f"   MAE: {test_metrics['mae']:.2f}")
    print(f"   MSE: {test_metrics['mse']:.2f}")
    print(f"   RMSE: {test_metrics['rmse']:.2f}")

    # MLflowã«æœ€çµ‚è©•ä¾¡æŒ‡æ¨™ã‚’è¨˜éŒ²
    log_final_metrics(use_mlflow, train_metrics, test_metrics)

    # ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¡¨ç¤º
    print("\nğŸ¯ ç‰¹å¾´é‡é‡è¦åº¦ (ä¸Šä½10ä»¶):")
    feature_importance = model.feature_importances_
    feature_names = x.columns.tolist()

    importance_pairs = list(zip(feature_names, feature_importance, strict=True))
    importance_pairs.sort(key=lambda x: x[1], reverse=True)

    for i, (feature_name, importance) in enumerate(importance_pairs[:10], 1):
        print(f"   {i:2d}. {feature_name:<30} {importance:.4f}")
        # MLflowã«ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¨˜éŒ²
        if use_mlflow:
            mlflow.log_metric(f"feature_importance_{feature_name}", importance)

    print("\nğŸ” éå­¦ç¿’ã®åˆ†æ:")
    overfitting = results["overfitting_analysis"]
    if overfitting["is_overfitting"]:
        print("   âš ï¸  éå­¦ç¿’ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        for reason in overfitting["reasons"]:
            print(f"      - {reason}")
    else:
        print("   âœ… éå­¦ç¿’ã®å…†å€™ã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“")

    print(f"   RÂ²ã®å·® (å­¦ç¿’ - ãƒ†ã‚¹ãƒˆ): {overfitting['r2_difference']:.4f}")
    print(f"   RMSEã®å·® (ãƒ†ã‚¹ãƒˆ - å­¦ç¿’): {overfitting['rmse_difference']:.2f}")

    # MLflowã«éå­¦ç¿’åˆ†æã‚’è¨˜éŒ²
    log_overfitting_analysis(use_mlflow, overfitting)

    # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    save_final_model(use_mlflow, pipeline, args.experiment_name, args.run_name)


if __name__ == "__main__":
    main()
