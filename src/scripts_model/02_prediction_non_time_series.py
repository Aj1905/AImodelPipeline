"""
ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸäºˆæ¸¬å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å®Ÿè¡Œä¾‹:
python src/scripts_model/02_prediction_non_time_series.py \
    --db-path data/database.sqlite \
    --predict-table new_data \
    --output-table predictions

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
    --db-path: SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    --predict-table: å…¥åŠ›ãƒ†ãƒ¼ãƒ–ãƒ«åï¼ˆç›®çš„å¤‰æ•°åˆ—ã¯ä¸è¦ï¼‰
    --output-table: äºˆæ¸¬çµæœã‚’æ›¸ãè¾¼ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«å
"""

import argparse
import sqlite3
import joblib
import json
from pathlib import Path

import pandas as pd
import polars as pl

# ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
ARTIFACT_DIR = Path("artifacts")

# æ—¢å­˜ã®åˆ—ã‚’ç‰¹å¾´é‡ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ãƒªã‚¹ãƒˆï¼ˆ01_model_non_time_series.pyã¨åŒã˜ï¼‰
FEATURE_COLUMNS = [
    "date_and_time",
    "prev_year_same_weekday_sales_daily_sum",
    "Yokohama_Sea_Level_Pressure",
    "time",
    "prev_year_same_date_sales_daily_sum",
    "time_flag",
    "date_day",
    "sales_trailing_ma_11",
    "Yokohama_Temperature",
    "Yokohama_Wind_Speed",
    "prev_year_same_weekday_sales",
    "sales_trailing_ma_1",
    "prev_year_same_weekday_sales_monthly_sum",
    "Yokohama_Relative_Humidity",
    "sales_trailing_ma_3",
    "prev_year_same_date_sales",
]

# feature_engineeringé–¢æ•°ã§ä½œæˆã™ã‚‹ç‰¹å¾´é‡ã®åå‰ï¼ˆ01_model_non_time_series.pyã¨åŒã˜ï¼‰
ENGINEERED_FEATURES = [
    "is_lunch",
    "weekday", 
    "time_category",
    "season"
]

def feature_engineering(data: pl.DataFrame) -> pl.DataFrame:
    """ä¸€éƒ¨ã®åˆ—ã‚’å¤‰æ›ã—ã€æ–°ãŸãªç‰¹å¾´é‡åˆ—ã‚’è¿”ã™ï¼ˆ01_model_non_time_series.pyã¨åŒã˜ï¼‰"""
    df = data.clone()

    # æ—¥ä»˜ã‚’datetimeå‹ã«å¤‰æ›
    df = df.with_columns(pl.col("date_and_time").str.to_datetime("%Y-%m-%d %H:%M:%S").alias("datetime"))

    # æ–°ã—ã„ç‰¹å¾´é‡ã‚’ä½œæˆ
    engineered = df.with_columns(
        [
            pl.when(pl.col("time").is_in([11, 12, 13])).then(1).otherwise(0).alias("is_lunch"),
            pl.col("datetime").dt.weekday().alias("weekday"),
            pl.when(pl.col("time") < 12)
            .then(0)
            .when(pl.col("time") < 15)
            .then(1)
            .when(pl.col("time") < 18)
            .then(2)
            .otherwise(3)
            .alias("time_category"),
            pl.when(pl.col("date_month").is_in([12, 1, 2]))
            .then(0)
            .when(pl.col("date_month").is_in([3, 4, 5]))
            .then(1)
            .when(pl.col("date_month").is_in([6, 7, 8]))
            .then(2)
            .otherwise(3)
            .alias("season"),
        ]
    )

    return engineered.select(ENGINEERED_FEATURES)

def main():
    parser = argparse.ArgumentParser(description="ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã™")
    parser.add_argument("--db-path",       type=str, required=True, help="SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--predict-table", type=str, required=True, help="å…¥åŠ›ãƒ†ãƒ¼ãƒ–ãƒ«åï¼ˆç›®çš„å¤‰æ•°åˆ—ã¯ä¸è¦ï¼‰")
    parser.add_argument("--output-table",  type=str, required=True, help="äºˆæ¸¬çµæœã‚’æ›¸ãè¾¼ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«å")
    args = parser.parse_args()

    # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆèª­ã¿è¾¼ã¿
    fm       = joblib.load(ARTIFACT_DIR/"feature_manager.pkl")
    tm       = joblib.load(ARTIFACT_DIR/"target_manager.pkl")
    model    = joblib.load(ARTIFACT_DIR/"model.pkl")
    metadata = json.load(open(ARTIFACT_DIR/"metadata.json", "r", encoding="utf-8"))

    print("ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æƒ…å ±:")
    print(f"   å…ƒã®ç‰¹å¾´é‡: {metadata.get('original_features', [])}")
    print(f"   ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ç‰¹å¾´é‡: {metadata.get('engineered_features', [])}")

    # æœ¬ç•ªãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    conn = sqlite3.connect(args.db_path)
    df = pd.read_sql(f"SELECT * FROM {args.predict_table}", conn)
    conn.close()
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­è¾¼å®Œäº†: {len(df)} è¡Œ, {len(df.columns)} åˆ—")

    # æŒ‡å®šã•ã‚ŒãŸç‰¹å¾´é‡ã®ã¿ã‚’é¸æŠ
    available_features = [col for col in FEATURE_COLUMNS if col in df.columns]
    missing_features = [col for col in FEATURE_COLUMNS if col not in df.columns]
    
    if missing_features:
        print(f"âš ï¸ æŒ‡å®šã•ã‚ŒãŸç‰¹å¾´é‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_features}")
    
    print(f"ğŸ“Š ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡: {available_features}")
    
    # æŒ‡å®šã•ã‚ŒãŸç‰¹å¾´é‡ã®ã¿ã‚’é¸æŠ
    df_selected = df[available_features].copy()
    
    # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
    print("ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
    df_pl = pl.from_pandas(df_selected)
    engineered_features = feature_engineering(df_pl)
    engineered_features_pd = engineered_features.to_pandas()
    
    # å…ƒã®ç‰¹å¾´é‡ã¨ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã•ã‚ŒãŸç‰¹å¾´é‡ã‚’çµåˆ
    X_input = pd.concat([df_selected[available_features], engineered_features_pd], axis=1)
    
    print(f"âœ… ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†: {len(X_input.columns)} åˆ—")
    print(f"   å…ƒã®ç‰¹å¾´é‡: {len(available_features)} åˆ—")
    print(f"   ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ç‰¹å¾´é‡: {len(ENGINEERED_FEATURES)} åˆ—")

    # å‰å‡¦ç† â†’ äºˆæ¸¬
    X_processed = fm.transform(X_input)
    y_pred = model.predict(X_processed)
    
    # äºˆæ¸¬çµæœã‚’å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ 
    target_col = metadata.get("target_column", "sales")
    df[target_col] = y_pred

    # çµæœæ›¸ãæˆ»ã—
    conn = sqlite3.connect(args.db_path)
    df.to_sql(args.output_table, conn, if_exists="replace", index=False)
    conn.close()

    print(f"âœ… äºˆæ¸¬çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ« '{args.output_table}' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    print(f"ğŸ“Š äºˆæ¸¬å€¤ã®çµ±è¨ˆ:")
    print(f"   å¹³å‡: {y_pred.mean():.2f}")
    print(f"   æ¨™æº–åå·®: {y_pred.std():.2f}")
    print(f"   æœ€å°å€¤: {y_pred.min():.2f}")
    print(f"   æœ€å¤§å€¤: {y_pred.max():.2f}")

if __name__ == "__main__":
    main()
